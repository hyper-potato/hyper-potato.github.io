<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Beginner&#39;s guide for predictive models - Hyper Potato&#39;s Blog</title>
        <meta name="Description" content="Hi, here is Nina"><meta property="og:title" content="Beginner&#39;s guide for predictive models" />
<meta property="og:description" content="In this post, I will apply decision tree, k-NN, SVM to predict the evaluation of the cars based on their characteristics. Dataset is from UCI ML Repository.
More specifically, I will explore how well these techniques perform for several different parameter values.
Present a brief overview of the predictive modeling process, explorations, and discuss my results. Then I will present the final model and discuss its performance in a comprehensive manner (overall accuracy; per-class performance, i." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hyper-potato.github.io/2019-10-06-car-evaluation-using-machine-learning/" />
<meta property="og:image" content="https://hyper-potato.github.io/logo.png"/>
<meta property="article:published_time" content="2019-10-06T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-10-06T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://hyper-potato.github.io/logo.png"/>

<meta name="twitter:title" content="Beginner&#39;s guide for predictive models"/>
<meta name="twitter:description" content="In this post, I will apply decision tree, k-NN, SVM to predict the evaluation of the cars based on their characteristics. Dataset is from UCI ML Repository.
More specifically, I will explore how well these techniques perform for several different parameter values.
Present a brief overview of the predictive modeling process, explorations, and discuss my results. Then I will present the final model and discuss its performance in a comprehensive manner (overall accuracy; per-class performance, i."/>
<meta name="application-name" content="Hyper Potato&#39;s Blog">
<meta name="apple-mobile-web-app-title" content="Hyper Potato&#39;s Blog"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://hyper-potato.github.io/2019-10-06-car-evaluation-using-machine-learning/" /><link rel="prev" href="https://hyper-potato.github.io/2019-08-27-hi-there/" /><link rel="next" href="https://hyper-potato.github.io/2019-11-02-money-ball-with-arules/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Beginner's guide for predictive models",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/hyper-potato.github.io\/2019-10-06-car-evaluation-using-machine-learning\/"
        },"image": {
                "@type": "ImageObject",
                "url": "https:\/\/hyper-potato.github.io\/cover.png",
                "width":  800 ,
                "height":  600 
            },"genre": "posts","keywords": "classification, machine learning","wordcount":  2104 ,
        "url": "https:\/\/hyper-potato.github.io\/2019-10-06-car-evaluation-using-machine-learning\/","datePublished": "2019-10-06T00:00:00+00:00","dateModified": "2019-10-06T00:00:00+00:00","publisher": {
                "@type": "Organization",
                "name": "xxxx",
                "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/hyper-potato.github.io\/logo.png",
                "width":  127 ,
                "height":  40 
                }
            },"author": {
                "@type": "Person",
                "name": "Nina"
            },"description": ""
    }
    </script></head>
    <body><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Hyper Potato&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading/small.min.svg"
        data-src="/images/me/robot.png"
        data-srcset="/images/me/robot.png, /images/me/robot.png 1.5x, /images/me/robot.png 2x"
        data-sizes="auto"
        alt="Hyper Potato&#39;s Blog"
        title="Hyper Potato&#39;s Blog" /><span class="header-title-pre"> </span>Hyper Potato&#39;s Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/about/"> About </a><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/leetcode/"> Leetcode </a><a class="menu-item" href="/"> Home </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Hyper Potato&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading/small.min.svg"
        data-src="/images/me/robot.png"
        data-srcset="/images/me/robot.png, /images/me/robot.png 1.5x, /images/me/robot.png 2x"
        data-sizes="auto"
        alt="Hyper Potato&#39;s Blog"
        title="Hyper Potato&#39;s Blog" /><span class="header-title-pre"> </span>Hyper Potato&#39;s Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/about/" title="">About</a><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/leetcode/" title="">Leetcode</a><a class="menu-item" href="/" title="">Home</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><article class="page single"><div class="details toc" id="toc-static">
              <div class="details-summary toc-title">
                  <span>Contents</span>
                  <span><i class="details-icon fas fa-angle-right"></i></span>
              </div>
              <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#data-exploration">Data Exploration</a></li>
    <li><a href="#initial-feature-exploration">Initial Feature Exploration</a></li>
    <li><a href="#encoding-and-data-spliting">Encoding and Data Spliting</a></li>
    <li><a href="#model-building">Model Building</a>
      <ul>
        <li><a href="#knn">KNN</a></li>
        <li><a href="#svm-grid-search">SVM Grid Search</a></li>
        <li><a href="#fit-svc-rbf">Fit SVC rbf</a>
          <ul>
            <li><a href="#learning-curve">Learning curve</a></li>
          </ul>
        </li>
        <li><a href="#decision-tree">Decision Tree</a></li>
        <li><a href="#random-forest">Random Forest</a>
          <ul>
            <li><a href="#baseline-model">Baseline Model</a></li>
            <li><a href="#fine-tune-hyperparameter">Fine Tune Hyperparameter</a></li>
            <li><a href="#deal-with-overfitting">Deal with overfitting</a></li>
            <li><a href="#feature-reduction">Feature Reduction</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#model-comparison">Model Comparison</a></li>
  </ul>
</nav></div>
          </div><h1 class="single-title animated flipInX">Beginner&#39;s guide for predictive models</h1><h2 class="single-subtitle">on used car evaluation</h2><div class="post-meta">
            <div class="post-meta-line">
                <span class="post-author">
                  <p>Nina</p>
                    
                </span>&nbsp;&nbsp;<time datetime=2019-10-06>2019-10-06</time>&nbsp;&nbsp;&nbsp;
                    <span class="post-category">included in&nbsp;<a href="/categories/machine-learning/">
                                <i class="far fa-folder fa-fw"></i><span>&nbsp;</span>Machine learning
                            </a></span></div>

        </div><div class="featured-image"><img
        class="lazyload"
        src="/svg/loading/normal.min.svg"
        data-src="/images/car_value/patrick-tomasso-QMDap1TAu0g-unsplash.jpg"
        data-srcset="/images/car_value/patrick-tomasso-QMDap1TAu0g-unsplash.jpg, /images/car_value/patrick-tomasso-QMDap1TAu0g-unsplash.jpg 1.5x, /images/car_value/patrick-tomasso-QMDap1TAu0g-unsplash.jpg 2x"
        data-sizes="auto"
        alt="/images/car_value/patrick-tomasso-QMDap1TAu0g-unsplash.jpg"
        title="/images/car_value/patrick-tomasso-QMDap1TAu0g-unsplash.jpg" /></div><div class="toc" id="toc-auto">
                <h2 class="toc-title">Contents</h2>
                <div class="toc-content" id="toc-content-auto"></div>
            </div><div class="content" id="content"><p>In this post, I will apply decision tree, k-NN, SVM to predict the evaluation of the cars based on their characteristics. Dataset is from <a href="https://archive.ics.uci.edu/ml/datasets/Car&#43;Evaluation" target="_blank" rel="noopener noreffer">UCI ML Repository</a>.</p>
<p>More specifically, I will explore how well these techniques perform for several different parameter values.</p>
<p>Present a brief overview of the predictive modeling process, explorations, and discuss my results. Then I will present the final model and discuss its performance in a comprehensive manner (overall accuracy; per-class performance, i.e., whether this model predicts all classes equally well, or if there some classes for which it does much better than others; etc.)</p>
<p>Let&rsquo;s hit the road.</p>
<h2 id="data-exploration">Data Exploration</h2>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#Importing the basic libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">plotly.offline</span> <span class="kn">as</span> <span class="nn">py</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1">#%config InlineBackend.figure_format = &#39;svg&#39;</span>

<span class="kn">from</span> <span class="nn">warnings</span> <span class="kn">import</span> <span class="n">simplefilter</span>
<span class="c1"># ignore all future warnings</span>
<span class="n">simplefilter</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">FutureWarning</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cars</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;car.data&#39;</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span>  <span class="p">[</span><span class="s1">&#39;buying&#39;</span><span class="p">,</span> <span class="s1">&#39;maint&#39;</span><span class="p">,</span> <span class="s1">&#39;doors&#39;</span><span class="p">,</span><span class="s1">&#39;capacity&#39;</span><span class="p">,</span><span class="s1">&#39;lug_boot&#39;</span><span class="p">,</span><span class="s1">&#39;safety&#39;</span><span class="p">,</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#Taking an overview of data</span>
<span class="n">cars</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>buying</th>
      <th>maint</th>
      <th>doors</th>
      <th>capacity</th>
      <th>lug_boot</th>
      <th>safety</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>975</th>
      <td>med</td>
      <td>high</td>
      <td>2</td>
      <td>2</td>
      <td>med</td>
      <td>low</td>
      <td>unacc</td>
    </tr>
    <tr>
      <th>277</th>
      <td>vhigh</td>
      <td>med</td>
      <td>4</td>
      <td>2</td>
      <td>big</td>
      <td>med</td>
      <td>unacc</td>
    </tr>
    <tr>
      <th>1219</th>
      <td>med</td>
      <td>low</td>
      <td>3</td>
      <td>2</td>
      <td>med</td>
      <td>med</td>
      <td>unacc</td>
    </tr>
    <tr>
      <th>1316</th>
      <td>low</td>
      <td>vhigh</td>
      <td>2</td>
      <td>more</td>
      <td>small</td>
      <td>high</td>
      <td>unacc</td>
    </tr>
    <tr>
      <th>249</th>
      <td>vhigh</td>
      <td>med</td>
      <td>3</td>
      <td>2</td>
      <td>big</td>
      <td>low</td>
      <td>unacc</td>
    </tr>
    <tr>
      <th>1712</th>
      <td>low</td>
      <td>low</td>
      <td>5more</td>
      <td>4</td>
      <td>small</td>
      <td>high</td>
      <td>good</td>
    </tr>
    <tr>
      <th>1676</th>
      <td>low</td>
      <td>low</td>
      <td>4</td>
      <td>2</td>
      <td>small</td>
      <td>high</td>
      <td>unacc</td>
    </tr>
    <tr>
      <th>1374</th>
      <td>low</td>
      <td>vhigh</td>
      <td>4</td>
      <td>more</td>
      <td>big</td>
      <td>low</td>
      <td>unacc</td>
    </tr>
    <tr>
      <th>1117</th>
      <td>med</td>
      <td>med</td>
      <td>3</td>
      <td>4</td>
      <td>small</td>
      <td>med</td>
      <td>acc</td>
    </tr>
    <tr>
      <th>541</th>
      <td>high</td>
      <td>high</td>
      <td>2</td>
      <td>2</td>
      <td>small</td>
      <td>med</td>
      <td>unacc</td>
    </tr>
  </tbody>
</table>
</div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cars</span><span class="o">.</span><span class="n">doors</span><span class="o">.</span><span class="n">replace</span><span class="p">((</span><span class="s1">&#39;5more&#39;</span><span class="p">),(</span><span class="s1">&#39;5&#39;</span><span class="p">),</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cars</span><span class="o">.</span><span class="n">capacity</span><span class="o">.</span><span class="n">replace</span><span class="p">((</span><span class="s1">&#39;more&#39;</span><span class="p">),(</span><span class="s1">&#39;5&#39;</span><span class="p">),</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cars</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>buying</th>
      <th>maint</th>
      <th>doors</th>
      <th>capacity</th>
      <th>lug_boot</th>
      <th>safety</th>
      <th>class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1728</td>
      <td>1728</td>
      <td>1728</td>
      <td>1728</td>
      <td>1728</td>
      <td>1728</td>
      <td>1728</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>4</td>
      <td>4</td>
      <td>4</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>4</td>
    </tr>
    <tr>
      <th>top</th>
      <td>med</td>
      <td>med</td>
      <td>2</td>
      <td>2</td>
      <td>med</td>
      <td>med</td>
      <td>unacc</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>432</td>
      <td>432</td>
      <td>432</td>
      <td>576</td>
      <td>576</td>
      <td>576</td>
      <td>1210</td>
    </tr>
  </tbody>
</table>
</div>
<p>The count for every feature is the same as the number of rows, which indicates no missing values.<br>
Yay!<br>
Since we are dealing with categorical data, we are shown the distinct values in the unique column.</p>
<p>The distribution of the acceptability of the cars.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#Lets find out the number of cars in each evaluation category</span>
<span class="n">cars</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</code></pre></div><pre><code>unacc    1210
acc       384
good       69
vgood      65
Name: class, dtype: int64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">cars</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_11_1.png"
        data-srcset="/images/car_value/output_11_1.png, /images/car_value/output_11_1.png 1.5x, /images/car_value/output_11_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<p>As we can see, our target varible is highly skewed</p>
<h2 id="initial-feature-exploration">Initial Feature Exploration</h2>
<p>So we need to predict the acceptability of the car given the 6 features. Let’s try to find the relationship between each feature variable with the target variable. I’ll use pandas crosstab to make a table showing the relationship and Plotly to plot an interactive graph for the same.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">buy</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">cars</span><span class="p">[</span><span class="s1">&#39;buying&#39;</span><span class="p">],</span> <span class="n">cars</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="n">maint</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">cars</span><span class="p">[</span><span class="s1">&#39;maint&#39;</span><span class="p">],</span> <span class="n">cars</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="n">drs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">cars</span><span class="p">[</span><span class="s1">&#39;doors&#39;</span><span class="p">],</span> <span class="n">cars</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="n">prsn</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">cars</span><span class="p">[</span><span class="s1">&#39;capacity&#39;</span><span class="p">],</span> <span class="n">cars</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="n">lb</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">cars</span><span class="p">[</span><span class="s1">&#39;lug_boot&#39;</span><span class="p">],</span> <span class="n">cars</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
<span class="n">sfty</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">cars</span><span class="p">[</span><span class="s1">&#39;safety&#39;</span><span class="p">],</span> <span class="n">cars</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">buy</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>class</th>
      <th>acc</th>
      <th>good</th>
      <th>unacc</th>
      <th>vgood</th>
    </tr>
    <tr>
      <th>buying</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>high</th>
      <td>108</td>
      <td>0</td>
      <td>324</td>
      <td>0</td>
    </tr>
    <tr>
      <th>low</th>
      <td>89</td>
      <td>46</td>
      <td>258</td>
      <td>39</td>
    </tr>
    <tr>
      <th>med</th>
      <td>115</td>
      <td>23</td>
      <td>268</td>
      <td>26</td>
    </tr>
    <tr>
      <th>vhigh</th>
      <td>72</td>
      <td>0</td>
      <td>360</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">buy</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">stacked</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_17_1.png"
        data-srcset="/images/car_value/output_17_1.png, /images/car_value/output_17_1.png 1.5x, /images/car_value/output_17_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">maint</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">stacked</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_18_1.png"
        data-srcset="/images/car_value/output_18_1.png, /images/car_value/output_18_1.png 1.5x, /images/car_value/output_18_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">drs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s1">&#39;bar&#39;</span><span class="p">,</span><span class="n">stacked</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_19_1.png"
        data-srcset="/images/car_value/output_19_1.png, /images/car_value/output_19_1.png 1.5x, /images/car_value/output_19_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">sfty</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">stacked</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_20_1.png"
        data-srcset="/images/car_value/output_20_1.png, /images/car_value/output_20_1.png 1.5x, /images/car_value/output_20_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<h2 id="encoding-and-data-spliting">Encoding and Data Spliting</h2>
<p>We need to encode the categorical data
There are two options, either we use label encoder or one hot encoder.
Intuitively, predictors&rsquo; value in the dataset such as &lsquo;low, med, high&rsquo; introduce an underlying linear order itself, therefore, it&rsquo;s alright to transform data with ordinal encoder.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cars1</span> <span class="o">=</span> <span class="n">cars</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">cars1</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">((</span><span class="s1">&#39;unacc&#39;</span><span class="p">,</span> <span class="s1">&#39;acc&#39;</span><span class="p">,</span> <span class="s1">&#39;good&#39;</span><span class="p">,</span> <span class="s1">&#39;vgood&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">cars1</span><span class="p">[</span><span class="s1">&#39;buying&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">((</span><span class="s1">&#39;vhigh&#39;</span><span class="p">,</span> <span class="s1">&#39;high&#39;</span><span class="p">,</span> <span class="s1">&#39;med&#39;</span><span class="p">,</span> <span class="s1">&#39;low&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">cars1</span><span class="p">[</span><span class="s1">&#39;maint&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">((</span><span class="s1">&#39;vhigh&#39;</span><span class="p">,</span> <span class="s1">&#39;high&#39;</span><span class="p">,</span> <span class="s1">&#39;med&#39;</span><span class="p">,</span> <span class="s1">&#39;low&#39;</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">cars1</span><span class="p">[</span><span class="s1">&#39;lug_boot&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">((</span><span class="s1">&#39;small&#39;</span><span class="p">,</span><span class="s1">&#39;med&#39;</span><span class="p">,</span><span class="s1">&#39;big&#39;</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">cars1</span><span class="p">[</span><span class="s1">&#39;safety&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">((</span><span class="s1">&#39;low&#39;</span><span class="p">,</span><span class="s1">&#39;med&#39;</span><span class="p">,</span><span class="s1">&#39;high&#39;</span><span class="p">),(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="s2">&#34;Feature Correlation:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">6.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">ax</span><span class="o">=</span><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cars1</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span><span class="n">center</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">vmax</span><span class="o">=.</span><span class="mi">3</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;YlGnBu&#34;</span><span class="p">,</span>
            <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div><pre><code>Feature Correlation:
</code></pre>
<p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="https://i.loli.net/2020/02/27/21gvpwnOc6FZaQ4.png"
        data-srcset="https://i.loli.net/2020/02/27/21gvpwnOc6FZaQ4.png, https://i.loli.net/2020/02/27/21gvpwnOc6FZaQ4.png 1.5x, https://i.loli.net/2020/02/27/21gvpwnOc6FZaQ4.png 2x"
        data-sizes="auto"
        alt="output_24_1.png"
        title="output_24_1.png" /></p>
<p>Ignoring the diagonal values, it can be seen that most of the columns shows very weak correlation with &lsquo;class&rsquo;. &lsquo;safety&rsquo; column is having a correlation with &lsquo;class&rsquo;.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#Dividing the dataframe into x features and y target variable</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">cars1</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;class&#39;</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">cars1</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X1_train</span><span class="p">,</span> <span class="n">X1_test</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">,</span> <span class="n">y1_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X3</span> <span class="o">=</span> <span class="n">cars</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;class&#39;</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y3</span> <span class="o">=</span> <span class="n">y1</span>
<span class="c1"># Using pandas dummies function to encode categorical data</span>

<span class="n">X3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span><span class="n">columns</span><span class="o">=</span> <span class="p">[</span><span class="s1">&#39;buying&#39;</span><span class="p">,</span><span class="s1">&#39;capacity&#39;</span><span class="p">,</span><span class="s1">&#39;doors&#39;</span><span class="p">,</span><span class="s1">&#39;maint&#39;</span><span class="p">,</span><span class="s1">&#39;lug_boot&#39;</span><span class="p">],</span>
                    <span class="n">prefix_sep</span><span class="o">=</span><span class="s1">&#39;_&#39;</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X3</span><span class="p">[</span><span class="s1">&#39;safety&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">((</span><span class="s1">&#39;low&#39;</span><span class="p">,</span><span class="s1">&#39;med&#39;</span><span class="p">,</span><span class="s1">&#39;high&#39;</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X3_train</span><span class="p">,</span> <span class="n">X3_test</span><span class="p">,</span> <span class="n">y3_train</span><span class="p">,</span> <span class="n">y3_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X3</span><span class="p">,</span> <span class="n">y3</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">41</span><span class="p">)</span>
</code></pre></div><br>
<h2 id="model-building">Model Building</h2>
<h3 id="knn">KNN</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>


<span class="c1">#create a dictionary of all values we want to test for n_neighbors</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">15</span><span class="p">)}</span>

<span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;# Tuning hyper-parameters for </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="n">knn_gscv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_micro&#39;</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span>
    <span class="n">knn_gscv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Best parameters set found on development set:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="n">knn_gscv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">Grid scores on development set:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="n">means</span> <span class="o">=</span> <span class="n">knn_gscv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
    <span class="n">stds</span> <span class="o">=</span> <span class="n">knn_gscv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">Detailed classification report:&#34;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">The model is trained on the full development set.&#34;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">The scores are computed on the full evaluation set.</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y1_test</span><span class="p">,</span> <span class="n">knn_gscv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1_test</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div><pre><code>                precision    recall  f1-score   support
           1       0.97      0.99      0.98       358
           2       0.90      0.88      0.89       118
           3       0.78      0.74      0.76        19
           4       0.89      0.67      0.76        24

    accuracy                           0.94       519
   macro avg       0.88      0.82      0.85       519
weighted avg       0.94      0.94      0.94       519
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Plot K vs accuracy</span>
<span class="n">avg_score</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">15</span><span class="p">):</span>
    <span class="n">knn</span><span class="o">=</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
    <span class="n">score</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
    <span class="n">avg_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">15</span><span class="p">),</span><span class="n">avg_score</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;n_neighbours&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;accuracy&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;K value vs Accuracy Plot&#34;</span><span class="p">)</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_44_1.png"
        data-srcset="/images/car_value/output_44_1.png, /images/car_value/output_44_1.png 1.5x, /images/car_value/output_44_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<p>Both grid search cross validation and plot show that neighbor = 5 is a potential good hyperparameter.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#Using KNN classifier,</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;minkowski&#39;</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">)</span>

<span class="n">y1_pred</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1_test</span><span class="p">)</span>
<span class="n">f1_KNN</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y1_test</span><span class="p">,</span><span class="n">y1_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Training Accuracy: &#34;</span><span class="p">,</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Testing Accuracy: &#34;</span><span class="p">,</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_test</span><span class="p">,</span> <span class="n">y1_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Cross-Validation Score :{0:.3f}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">))))</span>
</code></pre></div><pre><code>Training Accuracy:  0.9818031430934657
Testing Accuracy:  0.9421965317919075
Cross-Validation Score :0.813
</code></pre>
<h3 id="svm-grid-search">SVM Grid Search</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="c1"># Set the parameters by cross-validation</span>
<span class="n">parameters</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
               <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
               <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]},</span>
              <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">],</span>
               <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span>  <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]}]</span>

<span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">]</span>
<span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;# Tuning hyper-parameters for </span><span class="si">%s</span><span class="s2">&#34;</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span>
    <span class="k">print</span><span class="p">()</span>

    <span class="n">svc_gscv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_micro&#39;</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span>

    <span class="n">svc_gscv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Best parameters set found on development set:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="k">print</span><span class="p">(</span><span class="n">svc_gscv</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">Grid scores on development set:</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="n">means</span> <span class="o">=</span> <span class="n">svc_gscv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
    <span class="n">stds</span> <span class="o">=</span> <span class="n">svc_gscv</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">Detailed classification report:&#34;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">The model is trained on the full development set.&#34;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&#34;</span><span class="se">\n</span><span class="s2">The scores are computed on the full evaluation set.</span><span class="se">\n</span><span class="s2">&#34;</span><span class="p">)</span>

    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y1_test</span><span class="p">,</span> <span class="n">svc_gscv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1_test</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</code></pre></div><pre><code># Tuning hyper-parameters for precision

Best parameters set found on development set:

{'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}

Grid scores on development set:

Detailed classification report:
    
    The model is trained on the full development set.
    
    The scores are computed on the full evaluation set.
    
                  precision    recall  f1-score   support
    
               1       0.99      0.99      0.99       358
               2       0.96      0.95      0.95       118
               3       0.85      0.89      0.87        19
               4       0.92      0.92      0.92        24
    
        accuracy                           0.97       519
       macro avg       0.93      0.94      0.93       519
    weighted avg       0.98      0.97      0.98       519

# Tuning hyper-parameters for recall   
    Best parameters set found on development set:    
    {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}
 
 Grid scores on development set:
  
 Detailed classification report:
                  precision    recall  f1-score   support
               1       0.99      0.99      0.99       358
               2       0.96      0.95      0.95       118
               3       0.85      0.89      0.87        19
               4       0.92      0.92      0.92        24
    
        accuracy                           0.97       519
       macro avg       0.93      0.94      0.93       519
    weighted avg       0.98      0.97      0.98       519
</code></pre>
<h3 id="fit-svc-rbf">Fit SVC rbf</h3>
<p>From the GridSearch result, we find that with <code>kernel = 'rbf', C = 100, gamma = 0.1</code>, the model can achive best performance with respect to recall and accuracy. Since the unbalanced label of our target, I decide to go with recall, intuitively because we want to capture as many cars that will not be accepted as possible.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="n">svc_rbf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span> <span class="o">=</span> <span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">svc_rbf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">)</span>
<span class="n">y1_pred</span> <span class="o">=</span> <span class="n">svc_rbf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1_test</span><span class="p">)</span>
<span class="n">f1_SVC_rbf</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y1_test</span><span class="p">,</span><span class="n">y1_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Training Accuracy: &#34;</span><span class="p">,</span><span class="n">svc_rbf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Testing Accuracy: &#34;</span><span class="p">,</span> <span class="n">svc_rbf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_test</span><span class="p">,</span> <span class="n">y1_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Cross-Validation Score :{0:.3f}&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">svc_rbf</span><span class="p">,</span> <span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">))))</span>

</code></pre></div><pre><code>Training Accuracy:  0.9983457402812241
Testing Accuracy:  0.9749518304431599
Cross-Validation Score :0.877
</code></pre>
<h4 id="learning-curve">Learning curve</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">learning_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;Training examples&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;Score&#34;</span><span class="p">)</span>
<span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span> <span class="o">=</span> <span class="n">learning_curve</span><span class="p">(</span>
        <span class="n">svc_rbf</span><span class="p">,</span> <span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_scores_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_scores_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Learning Curves (SVM, RBF kernel,C=100, $\gamma=0.1$)&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span>
                     <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                     <span class="n">color</span><span class="o">=</span><span class="s2">&#34;r&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span> <span class="o">-</span> <span class="n">test_scores_std</span><span class="p">,</span>
                     <span class="n">test_scores_mean</span> <span class="o">+</span> <span class="n">test_scores_std</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;g&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;r&#34;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&#34;Training score&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;g&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;Cross-validation score&#34;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&#34;best&#34;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_55_0.png"
        data-srcset="/images/car_value/output_55_0.png, /images/car_value/output_55_0.png 1.5x, /images/car_value/output_55_0.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<h3 id="decision-tree">Decision Tree</h3>
<ol>
<li>ind Hyperparameter</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Plot max_depth vs accuracy</span>

<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>

<span class="n">avg_train</span><span class="o">=</span><span class="p">[]</span>
<span class="n">avg_test</span><span class="o">=</span><span class="p">[]</span>

<span class="k">for</span> <span class="n">max_depth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">11</span><span class="p">):</span>
    <span class="n">dtree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">)</span>
    <span class="n">train_score</span><span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">dtree</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
    <span class="n">test_score</span> <span class="o">=</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">dtree</span><span class="p">,</span><span class="n">X1_test</span><span class="p">,</span><span class="n">y1_test</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
    <span class="n">avg_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_score</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
    <span class="n">avg_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_score</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span> <span class="n">avg_train</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&#34;r&#34;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&#34;Training score&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">11</span><span class="p">),</span> <span class="n">avg_test</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&#34;g&#34;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;Test score&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;max_depth&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;accuracy&#34;</span><span class="p">)</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_61_1.png"
        data-srcset="/images/car_value/output_61_1.png, /images/car_value/output_61_1.png 1.5x, /images/car_value/output_61_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<p>Max depth of 9 looks to be a balanced cutoff point</p>
<ol start="2">
<li>Fit the model</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#Trying decision tree classifier</span>
<span class="n">dtree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
<span class="n">dtree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">y1_pred</span> <span class="o">=</span> <span class="n">dtree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1_test</span><span class="p">)</span>
<span class="n">F1_dtree</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y1_test</span><span class="p">,</span><span class="n">y1_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Training Accuracy: &#34;</span><span class="p">,</span><span class="n">dtree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Testing Accuracy: &#34;</span><span class="p">,</span> <span class="n">dtree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_test</span><span class="p">,</span> <span class="n">y1_test</span><span class="p">))</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y1_test</span><span class="p">,</span> <span class="n">y1_pred</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span><span class="n">cm</span><span class="p">,</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>Training Accuracy:  0.9842845326716294
Testing Accuracy:  0.9556840077071291
</code></pre>
<h3 id="random-forest">Random Forest</h3>
<h4 id="baseline-model">Baseline Model</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>

<span class="n">rfc</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">51</span><span class="p">)</span>

<span class="n">rfc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">)</span>
<span class="n">y1_pred</span> <span class="o">=</span> <span class="n">rfc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1_test</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Training Accuracy: &#34;</span><span class="p">,</span><span class="n">rfc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span> <span class="n">y1_train</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;Testing Accuracy: &#34;</span><span class="p">,</span> <span class="n">rfc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_test</span><span class="p">,</span> <span class="n">y1_test</span><span class="p">))</span>
</code></pre></div><pre><code>Training Accuracy:  1.0
Testing Accuracy:  0.9402697495183044
</code></pre>
<p>So, the basic model of RFC is giving 94% accuracy, but training score is clearly overfit. Now, check the effect of n_estimators on the model</p>
<h4 id="fine-tune-hyperparameter">Fine Tune Hyperparameter</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Plot number of trees vs accuracy</span>
<span class="n">n_tree</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">50</span><span class="p">,</span><span class="mi">100</span><span class="p">]</span>
<span class="n">curve</span> <span class="o">=</span> <span class="n">validation_curve</span><span class="p">(</span><span class="n">rfc</span><span class="p">,</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span><span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span>    <span class="n">param_range</span><span class="o">=</span><span class="n">n_tree</span><span class="p">)</span>
<span class="n">train_score</span><span class="o">=</span><span class="p">[</span><span class="n">curve</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">n_tree</span><span class="p">))]</span>
<span class="n">test_score</span><span class="o">=</span><span class="p">[</span><span class="n">curve</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">n_tree</span><span class="p">))]</span>

<span class="n">f</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_tree</span><span class="p">,</span><span class="n">train_score</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n_tree</span><span class="p">,</span><span class="n">test_score</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="o">=</span><span class="n">n_tree</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;n_estimators&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;accuracy&#34;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;number of trees vs Accuracy Plot&#34;</span><span class="p">)</span>
</code></pre></div><p>&lt;img src=&rsquo;/images/car_value/output_71_1.png&rsquo; width=&quot;200&rdquo;)</p>
<p>So, with the increasing n_estimators, test accuracy is increasing. Model is evaluating best at n_estimators=50. After n_estimators = 50, model starts overfitting.
Now, we&rsquo;ve reached approx. 97.1% accuracy.</p>
<p>Now, check how the model fits for various values of &lsquo;max_features&rsquo;</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">rfc</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">51</span><span class="p">)</span>
<span class="n">rfc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">param_range</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">curve</span><span class="o">=</span><span class="n">validation_curve</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">51</span><span class="p">),</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">param_name</span><span class="o">=</span><span class="s1">&#39;max_features&#39;</span><span class="p">,</span><span class="n">param_range</span><span class="o">=</span><span class="n">param_range</span><span class="p">)</span>

<span class="n">train_score</span><span class="o">=</span><span class="p">[</span><span class="n">curve</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">param_range</span><span class="p">))]</span>
<span class="n">test_score</span><span class="o">=</span><span class="p">[</span><span class="n">curve</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">param_range</span><span class="p">))]</span>
<span class="n">f</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">param_range</span><span class="p">,</span><span class="n">train_score</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;training&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">param_range</span><span class="p">,</span><span class="n">test_score</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="o">=</span><span class="n">param_range</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;validation_curve of random forest with 50 trees&#39;</span><span class="p">)</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_75_1.png"
        data-srcset="/images/car_value/output_75_1.png, /images/car_value/output_75_1.png 1.5x, /images/car_value/output_75_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<h4 id="deal-with-overfitting">Deal with overfitting</h4>
<p>From above graph, it is clear that model is giving best resut for max_features=5. Still the model is overfitting.</p>
<p>Now we&rsquo;ve reached 97.2% accuracy approx.</p>
<p>We can also check of other parameters like &lsquo;max_depth&rsquo;,&lsquo;criterion&rsquo;,etc using above code.Another simple way is to use GridSearch to get combination of best parameters. As this dataset is small, GridSearch will take less time to complete.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;criterion&#39;</span><span class="p">:[</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span><span class="s1">&#39;entropy&#39;</span><span class="p">],</span>
           <span class="s1">&#39;max_depth&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span>
           <span class="s1">&#39;max_features&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="s1">&#39;auto&#39;</span><span class="p">],</span>
           <span class="s1">&#39;max_leaf_nodes&#39;</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="bp">None</span><span class="p">],}</span>

<span class="n">grid</span><span class="o">=</span><span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">51</span><span class="p">),</span>
                  <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
<span class="n">F1_rfc</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y1_test</span><span class="p">,</span><span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">)</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X1_test</span><span class="p">),</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">)</span>
</code></pre></div><pre><code>{'criterion': 'entropy', 'max_depth': 20, 'max_features': 6, 'max_leaf_nodes': None}
0.9859387923904053
</code></pre>
<p>So, with above parameters for random forest model, we&rsquo;ve reached 98.6% accuracy.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">curve</span><span class="o">=</span><span class="n">learning_curve</span><span class="p">(</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                         <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span>
                                         <span class="n">max_features</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                                         <span class="n">max_depth</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                                         <span class="n">random_state</span><span class="o">=</span><span class="mi">51</span><span class="p">,</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="bp">None</span><span class="p">),</span>
                  <span class="n">X1_train</span><span class="p">,</span><span class="n">y1_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">size</span><span class="o">=</span><span class="n">curve</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">train_score</span><span class="o">=</span><span class="p">[</span><span class="n">curve</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">test_score</span><span class="o">=</span><span class="p">[</span><span class="n">curve</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">fig</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="n">train_score</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">size</span><span class="p">,</span><span class="n">test_score</span><span class="p">)</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_80_1.png"
        data-srcset="/images/car_value/output_80_1.png, /images/car_value/output_80_1.png 1.5x, /images/car_value/output_80_1.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<p>Model is overfitting as train accuracy is 1 ,but test accuracy is much less.</p>
<p>I&rsquo;ve already tried changing RFC parameters to tackle overfitting. But, still it is not reduced.To reduce variance, we can</p>
<ol>
<li>Increase number of samples. (It is clear from above graph that incresing number of samples will improve model)</li>
<li>Reduce number of features</li>
</ol>
<h4 id="feature-reduction">Feature Reduction</h4>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">feature_import</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">rfc</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="n">X1</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">feature_import</span><span class="p">)</span>
</code></pre></div><pre><code>     buying     maint     doors  capacity  lug_boot    safety
0  0.154819  0.151853  0.059702  0.251283  0.094677  0.287667
</code></pre>
<p>From feature importances, it is clear that &lsquo;doors&rsquo; feature is least important.
So, train our model excluding that feature.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">X1_train_new</span><span class="p">,</span> <span class="n">X1_test_new</span><span class="p">,</span> <span class="n">y1_train_new</span><span class="p">,</span> <span class="n">y1_test_new</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X1</span><span class="p">[[</span><span class="s1">&#39;buying&#39;</span><span class="p">,</span> <span class="s1">&#39;maint&#39;</span><span class="p">,</span> <span class="s1">&#39;capacity&#39;</span><span class="p">,</span> <span class="s1">&#39;lug_boot&#39;</span><span class="p">,</span> <span class="s1">&#39;safety&#39;</span><span class="p">]],</span>
    <span class="n">y1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">rfc1</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;entropy&#39;</span><span class="p">,</span><span class="n">max_features</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">51</span><span class="p">,</span>
    <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">rfc1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1_train_new</span><span class="p">,</span><span class="n">y1_train_new</span><span class="p">)</span>
<span class="n">rfc1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X1_test_new</span><span class="p">,</span><span class="n">y1_test_new</span><span class="p">)</span>
</code></pre></div><pre><code>0.930635838150289
</code></pre>
<p>Our data already has less features and even if we drop the least important feature, then also the accuracy is reducing to 93.06%</p>
<p>So, dropping a feature is not an option to reduce variance in our model.The only option we are left with is to get more data.</p>
<p>Conclusion:
Random Forest Classifier is the best suitable model for this data with following parameters:
n_estimators: 50
criterion: entropy
max_depth: 10
max_features: 4
max_leaf_nodes: None</p>
<p>We are able to achieve 98.6% accuracy with this model</p>
<h2 id="model-comparison">Model Comparison</h2>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">models</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;rbf SVC&#39;</span><span class="p">,</span><span class="s1">&#39;Logistic Regression&#39;</span><span class="p">,</span><span class="s1">&#39;Decision Tree&#39;</span><span class="p">,</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">]</span>
<span class="n">f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">f1_SVC_rbf</span><span class="p">,</span> <span class="n">f1_LR</span><span class="p">,</span> <span class="n">F1_dtree</span><span class="p">,</span><span class="n">f1_gnb</span><span class="p">,</span><span class="n">F1_rfc</span><span class="p">])</span>

<span class="n">y_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">models</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="n">y_pos</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">y_pos</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;rbf SVC&#39;</span><span class="p">,</span><span class="s1">&#39;Logistic Regression&#39;</span><span class="p">,</span><span class="s1">&#39;Decision Tree&#39;</span><span class="p">,</span><span class="s1">&#39;Naive Bayes&#39;</span><span class="p">,</span><span class="s1">&#39;Random Forest&#39;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="/images/car_value/output_90_0.png"
        data-srcset="/images/car_value/output_90_0.png, /images/car_value/output_90_0.png 1.5x, /images/car_value/output_90_0.png 2x"
        data-sizes="auto"
        alt="png"
        title="png" /></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">score</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([</span><span class="n">f1</span><span class="p">],</span><span class="n">columns</span><span class="o">=</span><span class="n">models</span><span class="p">)</span>
<span class="n">score</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>rbf SVC</th>
      <th>Logistic Regression</th>
      <th>Decision Tree</th>
      <th>Naive Bayes</th>
      <th>Random Forest</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0.974</td>
      <td>0.81</td>
      <td>0.96</td>
      <td>0.76</td>
      <td>0.986</td>
    </tr>
  </tbody>
</table>
</div>
<p><strong>Conclusion</strong>
SVM rbf Classifier and Random Forest are roughly equally suitable models for this classification context, however, be aware that Random Forest tends to show overfitting, and accuracy won&rsquo;t get better with trees growing or features reduction.</p>
<p>We are able to achieve 98.6% weighted accuracy with this model.</p>
<p>&ndash; END &ndash;</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span></span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://hyper-potato.github.io/2019-10-06-car-evaluation-using-machine-learning/" data-title="Beginner&#39;s guide for predictive models" data-hashtags="classification,machine learning"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://hyper-potato.github.io/2019-10-06-car-evaluation-using-machine-learning/" data-hashtag="classification"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://hyper-potato.github.io/2019-10-06-car-evaluation-using-machine-learning/"><i class="fab fa-linkedin fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/classification/">classification</a>,&nbsp;<a href="/tags/machine-learning/">machine learning</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/2019-08-27-hi-there/" class="prev" rel="prev" title="Hi there"><i class="fas fa-angle-left fa-fw"></i>Hi there</a>
            <a href="/2019-11-02-money-ball-with-arules/" class="next" rel="next" title="Moneyball on Dortmund with Association Rules">Moneyball on Dortmund with Association Rules<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2020</span><span class="author" itemprop="copyrightHolder">&nbsp;
                      Nina</div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript">
    window.config = {"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"headerMode":{"desktop":"fixed","mobile":"auto"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};
</script><script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=html5shiv%2CElement.prototype.closest%2CrequestAnimationFrame%2CCustomEvent%2CPromise%2CObject.entries%2CObject.assign%2CObject.values%2Cfetch%2CElement.prototype.after%2CArray.prototype.fill%2CIntersectionObserver%2CArray.from%2CArray.prototype.find%2CMath.sign"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/object-fit-images/ofi.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
