<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Categorical variables encoding in machine learning -Part1 - Hyper Potato&#39;s Blog</title>
        <meta name="Description" content="Hi, here is Nina"><meta property="og:title" content="Categorical variables encoding in machine learning -Part1" />
<meta property="og:description" content="In this part one blog about categorical encoding, I will be introducing some common encoding methods that I have explored and pros and cons for each of them.
TL; DR There is no &lsquo;one size fits all&rsquo;, and it usually depends on your data representations and requirements. If a variable has a lot of categories then a one-hot encoding scheme will produce many columns which can cause memory issues. In my experience relying on LightGBM/CatBoost is the best out-of-the-box method." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hyper-potato.github.io/2020-06-04-deal-with-categorical-variable/" />
<meta property="og:image" content="https://hyper-potato.github.io/logo.png"/>
<meta property="article:published_time" content="2020-06-04T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-06-04T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://hyper-potato.github.io/logo.png"/>

<meta name="twitter:title" content="Categorical variables encoding in machine learning -Part1"/>
<meta name="twitter:description" content="In this part one blog about categorical encoding, I will be introducing some common encoding methods that I have explored and pros and cons for each of them.
TL; DR There is no &lsquo;one size fits all&rsquo;, and it usually depends on your data representations and requirements. If a variable has a lot of categories then a one-hot encoding scheme will produce many columns which can cause memory issues. In my experience relying on LightGBM/CatBoost is the best out-of-the-box method."/>
<meta name="application-name" content="Hyper Potato&#39;s Blog">
<meta name="apple-mobile-web-app-title" content="Hyper Potato&#39;s Blog"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://hyper-potato.github.io/2020-06-04-deal-with-categorical-variable/" /><link rel="prev" href="https://hyper-potato.github.io/2020-05-11-isolation/" /><link rel="next" href="https://hyper-potato.github.io/2020-06-29-blog-with-github-hugo/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Categorical variables encoding in machine learning -Part1",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/hyper-potato.github.io\/2020-06-04-deal-with-categorical-variable\/"
        },"image": {
                "@type": "ImageObject",
                "url": "https:\/\/hyper-potato.github.io\/cover.png",
                "width":  800 ,
                "height":  600 
            },"genre": "posts","keywords": "machine learning, feature engineering","wordcount":  1245 ,
        "url": "https:\/\/hyper-potato.github.io\/2020-06-04-deal-with-categorical-variable\/","datePublished": "2020-06-04T00:00:00+00:00","dateModified": "2020-06-04T00:00:00+00:00","publisher": {
                "@type": "Organization",
                "name": "xxxx",
                "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/hyper-potato.github.io\/logo.png",
                "width":  127 ,
                "height":  40 
                }
            },"author": {
                "@type": "Person",
                "name": "Nina"
            },"description": ""
    }
    </script></head>
    <body><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Hyper Potato&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading/small.min.svg"
        data-src="/images/me/robot.png"
        data-srcset="/images/me/robot.png, /images/me/robot.png 1.5x, /images/me/robot.png 2x"
        data-sizes="auto"
        alt="Hyper Potato&#39;s Blog"
        title="Hyper Potato&#39;s Blog" /><span class="header-title-pre"> </span>Hyper Potato&#39;s Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/about/"> About </a><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/categories/"> Categories </a><a class="menu-item" href="/leetcode/"> Leetcode </a><a class="menu-item" href="/"> Home </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Hyper Potato&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading/small.min.svg"
        data-src="/images/me/robot.png"
        data-srcset="/images/me/robot.png, /images/me/robot.png 1.5x, /images/me/robot.png 2x"
        data-sizes="auto"
        alt="Hyper Potato&#39;s Blog"
        title="Hyper Potato&#39;s Blog" /><span class="header-title-pre"> </span>Hyper Potato&#39;s Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/about/" title="">About</a><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/categories/" title="">Categories</a><a class="menu-item" href="/leetcode/" title="">Leetcode</a><a class="menu-item" href="/" title="">Home</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><article class="page single"><div class="details toc" id="toc-static">
              <div class="details-summary toc-title">
                  <span>Contents</span>
                  <span><i class="details-icon fas fa-angle-right"></i></span>
              </div>
              <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#tl-dr">TL; DR</a></li>
    <li><a href="#one-hot-encoding">One-hot encoding</a></li>
    <li><a href="#label--encoding">Label  Encoding</a></li>
    <li><a href="#optimal-binning-in-tree-learners">Optimal Binning in tree-learners</a></li>
    <li><a href="#target-encoder-te">Target Encoder (TE)</a></li>
    <li><a href="#james-stein-encoder">James-Stein Encoder</a></li>
    <li><a href="#helmert-encoder">Helmert Encoder</a></li>
  </ul>
</nav></div>
          </div><h1 class="single-title animated flipInX">Categorical variables encoding in machine learning -Part1</h1><div class="post-meta">
            <div class="post-meta-line">
                <span class="post-author">
                  <p>Nina</p>
                    
                </span>&nbsp;&nbsp;<time datetime=2020-06-04>2020-06-04</time>&nbsp;&nbsp;&nbsp;
                    <span class="post-category">included in&nbsp;<a href="/categories/machine-learning/">
                                <i class="far fa-folder fa-fw"></i><span>&nbsp;</span>Machine learning
                            </a></span></div>

        </div><div class="featured-image"><img
        class="lazyload"
        src="/svg/loading/normal.min.svg"
        data-src="/images/categorical_header.jpg"
        data-srcset="/images/categorical_header.jpg, /images/categorical_header.jpg 1.5x, /images/categorical_header.jpg 2x"
        data-sizes="auto"
        alt="/images/categorical_header.jpg"
        title="/images/categorical_header.jpg" /></div><div class="toc" id="toc-auto">
                <h2 class="toc-title">Contents</h2>
                <div class="toc-content" id="toc-content-auto"></div>
            </div><div class="content" id="content"><p>In this part one blog about categorical encoding, I will be introducing some common encoding methods that I have explored and pros and cons for each of them.</p>
<h2 id="tl-dr">TL; DR</h2>
<p>There is no &lsquo;one size fits all&rsquo;, and it usually depends on your data representations and requirements. If a variable has a lot of categories then a one-hot encoding scheme will produce many columns which can cause memory issues. In my experience relying on LightGBM/CatBoost is the best out-of-the-box method. Label encoding is a road to nowhere in most scenarios and you should be careful using it. However if your categorical variable happens to be ordinal then you can and should represent it with increasing numbers (for example “cold” becomes 0, “mild” becomes 1, and “hot” becomes 2). word2vec and others such methods are cool and good but they require some fine-tuning and don’t always work out.</p>
<p>No matter what method do you choose, always consider how to deal with new categories in test data that not appear in train data.</p>
<h2 id="one-hot-encoding">One-hot encoding</h2>
<p>Assume we all have prior knowledge about creating dummy variables for categorical data.</p>
<p>I am being judgemental and personally not a fan for OHE for two reasons:</p>
<ol>
<li>
<p>One-hot encoding might not be the best way to preprocess the data, especially for <strong>tree-based learners</strong>.  For high-cardinality categorical features, a tree built on one-hot features tends to be unbalanced and needs to grow very deeeeep to achieve good accuracy.</p>
</li>
<li>
<p>There will be mismatch in train and test set. Specifically, after one-hot encoding the number of columns in the training and test set data can be unequal, and therefore, the model will throw error during predicting.</p>
</li>
</ol>
<p>Workaround:</p>
<ol>
<li>Get the missing columns and add them to the test dataset: (thanks to answer from <a href="https://stackoverflow.com/questions/41335718/keep-same-dummy-variable-in-training-and-testing-data" target="_blank" rel="noopener noreffer">stackoverflow</a></li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Get missing columns in the training test</span>
<span class="n">missing_cols</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span> <span class="n">train</span><span class="o">.</span><span class="n">columns</span> <span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span> <span class="n">test</span><span class="o">.</span><span class="n">columns</span> <span class="p">)</span>
<span class="c1"># Add a missing column in test set with default value equal to 0</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">missing_cols</span><span class="p">:</span>
    <span class="n">test</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="c1"># Ensure the order of column in the test set is in the same order than in train set</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p>This code also ensure that column resulting from category in the test dataset but not present in the training dataset will be removed.</p>
<h2 id="label--encoding">Label  Encoding</h2>
<p>One common way to deal with categories is to simply map each category with a number. By applying such transformation, a model would treat categories as ordered integers, which in some cases is wrong. Such transformation should not be used “as is” for several types of models (Linear Models, KNN, Neural Nets, etc.).</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Code for encoding multiple categorical columns</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="n">le</span><span class="o">=</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="c1"># Iterating over all the common columns in train and test</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X_test</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">:</span>
    <span class="c1"># Encoding only categorical variables</span>
    <span class="k">if</span> <span class="n">X_test</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">dtypes</span><span class="o">==</span><span class="s1">&#39;object&#39;</span><span class="p">:</span>
    <span class="c1"># Using whole data to form an exhaustive list of levels</span>
    <span class="n">data</span><span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
    <span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
    <span class="n">X_test</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="n">col</span><span class="p">])</span>
</code></pre></div><h2 id="optimal-binning-in-tree-learners">Optimal Binning in tree-learners</h2>
<p>LightGBM or CatBoost have built-in <a href="https://github.com/Microsoft/LightGBM/blob/master/docs/Advanced-Topics.rst#categorical-feature-support" target="_blank" rel="noopener noreffer">Optimal binning</a> which is very convinent and well-performed. In fact in my experience relying on LightGBM/CatBoost is the best out-of-the-box method. While applying gradient boosting it could be used only if the type of a column is specified as <a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html" target="_blank" rel="noopener noreffer"><em>“category”</em></a>. New categories in Label Encoder are replaced with “-1” or None. If you are working with gradient boosting model  (especially Lightgbm) , LE is the simplest way to work with categories in terms of memory (the <strong>category type in python consumes much less memory than the object type</strong>).</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">category_col</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="s1">&#39;object&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">category_col</span><span class="p">:</span>
        <span class="n">X_train</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
        <span class="n">X_test</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">c</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;category&#39;</span><span class="p">)</span>
        
<span class="n">d_train</span> <span class="o">=</span> <span class="n">lgb</span><span class="o">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span>
                      <span class="n">free_raw_data</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
                      <span class="n">feature_name</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
                      <span class="n">categorical_feature</span><span class="o">=</span><span class="n">cat_col</span><span class="p">)</span> <span class="c1"># specify categorical columns while forming train and valid data matrix</span>
</code></pre></div><p>Upon further reflection, for LightGBM, it looks like simply using the <a href="https://github.com/Microsoft/LightGBM/blob/master/docs/Features.rst#optimal-split-for-categorical-features" target="_blank" rel="noopener noreffer">built-in categorical encoding</a> is outperforming any kind of categorical encoding I can personally do.</p>
<h2 id="target-encoder-te">Target Encoder (TE)</h2>
<p>I have encoutered many TE on kaggle winners solutions so I decided to try it out. It takes information about the target to encode categories, which makes it extremely powerful. The encoded category values are calculated according to the following formulas:</p>
<p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="https://miro.medium.com/max/772/1*CQ0CSJY8yBq0P0L4i2ztwQ.png"
        data-srcset="https://miro.medium.com/max/772/1*CQ0CSJY8yBq0P0L4i2ztwQ.png, https://miro.medium.com/max/772/1*CQ0CSJY8yBq0P0L4i2ztwQ.png 1.5x, https://miro.medium.com/max/772/1*CQ0CSJY8yBq0P0L4i2ztwQ.png 2x"
        data-sizes="auto"
        alt="https://miro.medium.com/max/772/1*CQ0CSJY8yBq0P0L4i2ztwQ.png"
        title="https://miro.medium.com/max/772/1*CQ0CSJY8yBq0P0L4i2ztwQ.png" /></p>
<p>Target encoding is a fast way to get the most out of your categorical variables with little effort. The idea is quite simple. Say we can have a categorical variable $X$ and a target $Y$. For each distinct element in $X$  we&rsquo;re going to compute the average of the corresponding values in $Y$ (It doesn&rsquo;t matter whether Y is continuous or binary). Then we&rsquo;re going to replace each $X_i$ with the according mean. This is rather easy to do in Python and the <code>pandas</code> library.</p>
<p>First let’s create some dummy data.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;x_0&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;a&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s1">&#39;x_1&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;d&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s1">&#39;y&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]})</span>
</code></pre></div><p>Here&rsquo;s how data looks like.</p>
<table>
<thead>
<tr>
<th></th>
<th>x_0</th>
<th>x_1</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>a</td>
<td>c</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>a</td>
<td>d</td>
<td>1</td>
</tr>
<tr>
<td>2</td>
<td>a</td>
<td>d</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>b</td>
<td>d</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>b</td>
<td>d</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>b</td>
<td>d</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Replace each value in x_0 with the matching mean.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="p">[</span><span class="s1">&#39;x_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;x_0&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;x_0&#39;</span><span class="p">)[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;x_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;x_1&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;x_1&#39;</span><span class="p">)[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</code></pre></div><p>We now have the following data frame.</p>
<table>
<thead>
<tr>
<th></th>
<th>x_0</th>
<th>x_1</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0.666667</td>
<td>1.0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>0.666667</td>
<td>0.4</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>0.666667</td>
<td>0.4</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>0.333333</td>
<td>0.4</td>
<td>0</td>
</tr>
<tr>
<td>4</td>
<td>0.333333</td>
<td>0.4</td>
<td>1</td>
</tr>
<tr>
<td>5</td>
<td>0.333333</td>
<td>0.4</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Target encoding is good because it picks up values that can explain the target.</p>
<p>In this vanilla example value a of variable x_0 has an average target value of 0.67. This can greatly help the machine learning classifications algorithms used downstream.</p>
<p>The problem of target encoding is <strong>target leakage</strong>. It uses information about the target. Because of the target leakage, model <strong>overfits</strong> the training data.</p>
<p>In the example, the value d of variable x_1 is replaced with a 1 because it only appears once and the corresponding value of y is a 1. In this case we’re over-fitting because we don’t have enough values to be <em>sure</em> that 1 is in fact the mean value of y when x_1 is equal to d. In other words only relying on each group mean is too reckless.</p>
<p>A popular way to reduce target leakage is to use cross-validation and compute the means in each out-of-fold dataset. This is <a href="http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging/target-encoding.html" target="_blank" rel="noopener noreffer">what H20 does</a> and what many Kagglers do too. Another approach is to use <a href="https://www.wikiwand.com/en/Additive_smoothing" target="_blank" rel="noopener noreffer">additive smoothing</a>. This is supposedly <a href="https://www.wikiwand.com/en/Bayes_estimator#/Practical_example_of_Bayes_estimators" target="_blank" rel="noopener noreffer">what IMDB uses to rate it’s movies</a>.</p>
<h2 id="james-stein-encoder">James-Stein Encoder</h2>
<p>James-Stein Encoder is a target-based encoder. The idea behind James-Stein Encoder is simple. Encoding is aimed to improve the estimation of the category’s mean target (first member of the amount) by shrinking them towards a more central average (second member of the amount). See more in the <a href="http://contrib.scikit-learn.org/category_encoders/jamesstein.html" target="_blank" rel="noopener noreffer">document</a>.</p>
<h2 id="helmert-encoder">Helmert Encoder</h2>
<p>Helmert coding compares each level of a categorical variable to the mean of the subsequent levels. Hence, the first contrast compares the mean of the dependent variable for “A” with the mean of all of the subsequent levels of categorical column (“B”, “C”, “D”), the second contrast compares the mean of the dependent variable for “B” with the mean of all of the subsequent levels (“C”, “D”), and the third contrast compares the mean of the dependent variable for “C” with the mean of all of the subsequent levels (in our case only one level — “D”).</p>
<p>This type of encoding can be useful in certain situations where levels of the categorical variable are ordered, say, from lowest to highest, or from smallest to largest.</p>
<hr>
<p>Reference</p>
<p><a href="https://www.kaggle.com/c/avito-demand-prediction/discussion/55521">https://www.kaggle.com/c/avito-demand-prediction/discussion/55521</a></p>
<p><a href="https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features">https://www.kaggle.com/ogrellier/python-target-encoding-for-categorical-features</a></p>
<p><a href="https://stackoverflow.com/questions/21057621/sklearn-labelencoder-with-never-seen-before-values">https://stackoverflow.com/questions/21057621/sklearn-labelencoder-with-never-seen-before-values</a></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span></span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/2020-06-04-deal-with-categorical-variable/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://hyper-potato.github.io/2020-06-04-deal-with-categorical-variable/" data-title="Categorical variables encoding in machine learning -Part1" data-hashtags="machine learning,feature engineering"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://hyper-potato.github.io/2020-06-04-deal-with-categorical-variable/" data-hashtag="machine learning"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://hyper-potato.github.io/2020-06-04-deal-with-categorical-variable/"><i class="fab fa-linkedin fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/machine-learning/">machine learning</a>,&nbsp;<a href="/tags/feature-engineering/">feature engineering</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/2020-05-11-isolation/" class="prev" rel="prev" title="Day 60 but who&#39;s keeping count"><i class="fas fa-angle-left fa-fw"></i>Day 60 but who&#39;s keeping count</a>
            <a href="/2020-06-29-blog-with-github-hugo/" class="next" rel="next" title="Build your blog with Github &#43; Hugo Part 1">Build your blog with Github &#43; Hugo Part 1<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>

</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2020</span><span class="author" itemprop="copyrightHolder">&nbsp;
                      Nina</div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/lightgallery/lightgallery.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><style>.lg-toolbar .lg-icon::after { color: #999; }</style><script type="text/javascript">
    window.config = {"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"headerMode":{"desktop":"fixed","mobile":"auto"},"lightGallery":{"actualSize":false,"exThumbImage":"data-thumbnail","hideBarsDelay":2000,"selector":".lightgallery","speed":400,"thumbContHeight":80,"thumbWidth":80,"thumbnail":true},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"},"twemoji":true};
</script><script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=html5shiv%2CElement.prototype.closest%2CrequestAnimationFrame%2CCustomEvent%2CPromise%2CObject.entries%2CObject.assign%2CObject.values%2Cfetch%2CElement.prototype.after%2CArray.prototype.fill%2CIntersectionObserver%2CArray.from%2CArray.prototype.find%2CMath.sign"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/object-fit-images/ofi.min.js"></script><script type="text/javascript" src="/lib/twemoji/twemoji.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lightgallery.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-thumbnail.min.js"></script><script type="text/javascript" src="/lib/lightgallery/lg-zoom.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
