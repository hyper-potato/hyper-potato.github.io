<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Predicting Visitors for Restaurants - Hyper Potato&#39;s Blog</title>
        <meta name="Description" content="Hi, here is Nina"><meta property="og:title" content="Predicting Visitors for Restaurants" />
<meta property="og:description" content="For Suckers for Sashimi Like Me!
1. Project Definition &amp; Introduction When someone opens a restaurant, their focus is likely on making high-quality food that will make their customers happy. However, this does not cover all the problems they encounter. How do they effectively schedule the staff? How do they know the quantity of ingredients to order? If restaurants cannot solve these problems, their business will be hurt.
If restaurants can predict how many visitors will be in one day, it&rsquo;s easier for them to make the arrangement." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://hyper-potato.github.io/2019-11-12-restaurants-visitors-predictive-model/" />
<meta property="og:image" content="https://hyper-potato.github.io/logo.png"/>
<meta property="article:published_time" content="2019-11-12T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-11-12T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://hyper-potato.github.io/logo.png"/>

<meta name="twitter:title" content="Predicting Visitors for Restaurants"/>
<meta name="twitter:description" content="For Suckers for Sashimi Like Me!
1. Project Definition &amp; Introduction When someone opens a restaurant, their focus is likely on making high-quality food that will make their customers happy. However, this does not cover all the problems they encounter. How do they effectively schedule the staff? How do they know the quantity of ingredients to order? If restaurants cannot solve these problems, their business will be hurt.
If restaurants can predict how many visitors will be in one day, it&rsquo;s easier for them to make the arrangement."/>
<meta name="application-name" content="Hyper Potato&#39;s Blog">
<meta name="apple-mobile-web-app-title" content="Hyper Potato&#39;s Blog"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="https://hyper-potato.github.io/2019-11-12-restaurants-visitors-predictive-model/" /><link rel="prev" href="https://hyper-potato.github.io/2019-11-02-money-ball-with-arules/" /><link rel="next" href="https://hyper-potato.github.io/2019-11-28-cat-or-dog-classification-dnn/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Predicting Visitors for Restaurants",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "https:\/\/hyper-potato.github.io\/2019-11-12-restaurants-visitors-predictive-model\/"
        },"image": {
                "@type": "ImageObject",
                "url": "https:\/\/hyper-potato.github.io\/cover.png",
                "width":  800 ,
                "height":  600 
            },"genre": "posts","keywords": "machine learning, Time Series Forecasting, regression","wordcount":  5564 ,
        "url": "https:\/\/hyper-potato.github.io\/2019-11-12-restaurants-visitors-predictive-model\/","datePublished": "2019-11-12T00:00:00+00:00","dateModified": "2019-11-12T00:00:00+00:00","publisher": {
                "@type": "Organization",
                "name": "xxxx",
                "logo": {
                "@type": "ImageObject",
                "url": "https:\/\/hyper-potato.github.io\/logo.png",
                "width":  127 ,
                "height":  40 
                }
            },"author": {
                "@type": "Person",
                "name": "Nina"
            },"description": ""
    }
    </script></head>
    <body><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Hyper Potato&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading/small.min.svg"
        data-src="/images/me/robot.png"
        data-srcset="/images/me/robot.png, /images/me/robot.png 1.5x, /images/me/robot.png 2x"
        data-sizes="auto"
        alt="Hyper Potato&#39;s Blog"
        title="Hyper Potato&#39;s Blog" /><span class="header-title-pre"> </span>Hyper Potato&#39;s Blog</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/about/"> About </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Hyper Potato&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading/small.min.svg"
        data-src="/images/me/robot.png"
        data-srcset="/images/me/robot.png, /images/me/robot.png 1.5x, /images/me/robot.png 2x"
        data-sizes="auto"
        alt="Hyper Potato&#39;s Blog"
        title="Hyper Potato&#39;s Blog" /><span class="header-title-pre"> </span>Hyper Potato&#39;s Blog</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/about/" title="">About</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Predicting Visitors for Restaurants</h1><h2 class="single-subtitle">For suckers for Sashimi like me!</h2><div class="post-meta">
            <div class="post-meta-line">
                <span class="post-author">
                  <p><i class="far fa-hand-spock fa-fw"></i> Nina</p>
                    
                </span>&nbsp;<time datetime=2019-11-12>2019-11-12</time>&nbsp;&nbsp;
                    <span class="post-category">included in<a href="/categories/machine-learning/">
                                <i class="far fa-folder fa-fw"></i>machine learning
                            </a>&nbsp;<a href="/categories/predictive-modeling/">
                                <i class="far fa-folder fa-fw"></i>predictive modeling
                            </a></span></div>
            
        </div><div class="featured-image"><img
        class="lazyload"
        src="/svg/loading/normal.min.svg"
        data-src="/images/post-sushi-set-japanese.jpg"
        data-srcset="/images/post-sushi-set-japanese.jpg, /images/post-sushi-set-japanese.jpg 1.5x, /images/post-sushi-set-japanese.jpg 2x"
        data-sizes="auto"
        alt="/images/post-sushi-set-japanese.jpg"
        title="/images/post-sushi-set-japanese.jpg" /></div><div class="details toc" id="toc-static">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-project-definition--introduction">1. Project Definition &amp; Introduction</a>
      <ul>
        <li><a href="#data-sources">Data Sources</a></li>
        <li><a href="#file-descriptions">File Descriptions</a></li>
        <li><a href="#model-summary">Model Summary</a></li>
        <li><a href="#analysis-flow">Analysis Flow</a></li>
      </ul>
    </li>
    <li><a href="#2-feature-engineering">2. Feature Engineering</a>
      <ul>
        <li><a href="#time-series-features">Time Series Features</a></li>
        <li><a href="#visit-features">Visit Features</a></li>
        <li><a href="#geographical-features">Geographical Features</a></li>
        <li><a href="#data-cleaning">Data Cleaning</a>
          <ul>
            <li><a href="#outliers">Outliers</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#3-modeling">3. Modeling</a>
      <ul>
        <li><a href="#arima">ARIMA</a></li>
        <li><a href="#prophet">Prophet</a></li>
        <li><a href="#lightgbm">LightGBM</a></li>
        <li><a href="#lstm-seq2seq--encoderdecoder">LSTM seq2seq + Encoder/Decoder</a>
          <ul>
            <li><a href="#motivation"><strong>Motivation</strong></a></li>
            <li><a href="#data-preparation"><strong>Data Preparation</strong></a></li>
            <li><a href="#model"><strong>Model</strong></a></li>
          </ul>
        </li>
        <li><a href="#evaluation">Evaluation</a></li>
      </ul>
    </li>
    <li><a href="#4-business-insight">4. Business Insight</a></li>
    <li><a href="#5-limitations--next-steps">5. Limitations &amp; Next Steps</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p><strong>For Suckers for Sashimi Like Me!</strong></p>
<h2 id="1-project-definition--introduction">1. Project Definition &amp; Introduction</h2>
<p>When someone opens a restaurant, their focus is likely on making high-quality food that will make their customers happy. However, this does not cover all the problems they encounter. How do they effectively schedule the staff? How do they know the quantity of ingredients to order? If restaurants cannot solve these problems, their business will be hurt.</p>
<p>If restaurants can predict how many visitors will be in one day, it&rsquo;s easier for them to make the arrangement. However, forecasting the number of visits is hard because it might be influenced by countless factors  (eg weather, holiday, and location). It&rsquo;s even harder for new restaurants with little historical data to make accurate predictions.</p>
<p>We are going to use reservation and visitation data to predict the total number of visitors to a restaurant for future dates. This information will help restaurants be more efficient and allow them to focus on creating an enjoyable dining experience for their customers.</p>
<h3 id="data-sources">Data Sources</h3>
<p>The following information was taken straight from the Kaggle prompt:</p>
<p>Our data comes from two separate sites and can be downloaded from <a href="https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting" target="_blank" rel="noopener noreffer">Kaggle</a>:</p>
<ul>
<li><code>Hot Pepper Gourmet (hpg)</code>: similar to Yelp, here users can search restaurants and also make a reservation online</li>
<li><code>AirREGI / Restaurant Board (air)</code>: similar to Square, a reservation control and cash register system</li>
</ul>
<p>We use historical visits, reservations, and store information from both sites to forecast the daily number of visitors for certain restaurants on given dates.</p>
<p>The training data covers the dates from 2016 until April 2017. The test set covers the last week of April and May of 2017. The test set is split based on time (the public fold coming first, the private fold following the public) and covers a chosen subset of the air restaurants.</p>
<p>Note that the test set intentionally spans a holiday week in Japan called the <code>Golden Week</code>.&rdquo; Also there are days in both training and test set where the restaurant were closed and had no visitors. The training set omits days where the restaurants were closed, and in testing set, they are ignored in scoring.</p>
<h3 id="file-descriptions">File Descriptions</h3>
<p>As mentioned above, there are datasets from two separate systems. Each file is prefaced with the source (either<code>air</code> or <code>hpg</code>) to indicate its origin. Each restaurant is associated with a unique <code>air_store_id</code> and <code>hpg_store_id</code>. Note that not all restaurants are covered by both systems, and that we have been provided data beyond restaurants for which we make predictions on. Latitudes and Longitudes are not exact to discourage de-identification of restaurants. (The file description details are from the <a href="https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/data" target="_blank" rel="noopener noreffer">website</a> introduction)</p>
<p><strong>air_reserve.csv</strong></p>
<p>This file contains reservations made in the air system.</p>
<ul>
<li><code>air_store_id</code> - the restaurant&rsquo;s id in the air system</li>
<li><code>visit_datetime</code> - the date and time of the visit for the reservation</li>
<li><code>reserve_datetime</code> - the date and time a reservation was made</li>
<li><code>reserve_visitors</code> - the number of visitors for that reservation</li>
</ul>
<p><strong>hpg_reserve.csv</strong></p>
<p>This file contains reservations made in the hpg system.</p>
<ul>
<li><code>hpg_store_id</code> - the restaurant&rsquo;s id in the hpg system</li>
<li><code>visit_datetime</code> - the date and time of visit for the reservation</li>
<li><code>reserve_datetime</code> - the date and time a reservation was made</li>
<li><code>reserve_visitors</code> - the number of visitors for that reservation</li>
</ul>
<p><strong>air_store_info.csv</strong></p>
<p>This file contains stores information in the air system. Column names and contents are self-explanatory. Note the latitude and longitude are geographical information of the area to which the store belongs.</p>
<ul>
<li><code>air_store_id</code></li>
<li><code>air_genre_name</code></li>
<li><code>air_area_name</code></li>
<li><code>latitude</code></li>
<li><code>longitude</code></li>
</ul>
<p><strong>hpg_store_info.csv</strong></p>
<p>This file contains stores information in the hpg system. Column names and contents are self-explanatory. Note: latitude and longitude are the latitude and longitude of the area to which the store belongs.</p>
<ul>
<li><code>hpg_store_id</code></li>
<li><code>hpg_genre_name</code></li>
<li><code>hpg_area_name</code></li>
<li><code>latitude</code></li>
<li><code>longitude</code></li>
</ul>
<p><strong>store_id_relation.csv</strong></p>
<p>This file allows you to join select restaurants that have both the air and hpg system. ‌</p>
<ul>
<li><code>hpg_store_id</code></li>
<li><code>air_store_id</code></li>
</ul>
<p><strong>air_visit_data.csv</strong></p>
<p>This file contains historical visit data for the air restaurants.</p>
<ul>
<li><code>air_store_id</code></li>
<li><code>visit_date</code> - the date</li>
<li><code>visitors</code> - the number of visitors to the restaurant on the date</li>
</ul>
<p><strong>date_info.csv</strong></p>
<p>This file shows a submission in the correct format, including the days for which you must forecast.</p>
<ul>
<li><code>calendar_date</code></li>
<li><code>day_of_week</code></li>
<li><code>holiday_flg</code> - is the day a holiday in Japan</li>
</ul>
<p><strong>sample_submission.csv</strong></p>
<p>This file shows a submission in the correct format, including the days for which you must forecast.</p>
<ul>
<li><code>id</code> - the id is formed by concatenating the air_store_id and visit_date with an underscore</li>
<li><code>visitors</code>- the number of visitors forecasted for the store and date combination</li>
</ul>
<h3 id="model-summary">Model Summary</h3>
<table>
<thead>
<tr>
<th align="left">Models Name</th>
<th>ERROR(RMSLE)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">ARIMA</td>
<td>0.56137</td>
</tr>
<tr>
<td align="left">PROPHET</td>
<td>0.54208</td>
</tr>
<tr>
<td align="left">LIHGT GBM(LGBM)</td>
<td>0.52412</td>
</tr>
<tr>
<td align="left">LSTM SEQ2SEQ</td>
<td>0.50277</td>
</tr>
<tr>
<td align="left"><strong>LSTM + LGBM</strong></td>
<td><strong>0.50002</strong></td>
</tr>
</tbody>
</table>
<p>We started by using ARIMA and PROPHET as our baseline model. Both are typical models when facing time-series related problem. However, the typical model can&rsquo;t take external data we have into account such as weather and store location. We decided to use other models that are capable of overcoming these challenges.</p>
<p>We also decided to try some ensembling methods. Light GBM is a very popular model and also gives good performance. We also included LSTM which is another traditional model for time-series prediction. Finally, we got a RMSLE with 0.50002 with a combination of LSTM and LGBM.</p>
<h3 id="analysis-flow">Analysis Flow</h3>
<p>We are following a very standard machine learning process which can be concluded as below chart:</p>
<p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="https://hackernoon.com/hn-images/1*oU3LAye3LxFcHg0UePmbSA.png"
        data-srcset="https://hackernoon.com/hn-images/1*oU3LAye3LxFcHg0UePmbSA.png, https://hackernoon.com/hn-images/1*oU3LAye3LxFcHg0UePmbSA.png 1.5x, https://hackernoon.com/hn-images/1*oU3LAye3LxFcHg0UePmbSA.png 2x"
        data-sizes="auto"
        alt="https://hackernoon.com/hn-images/1*oU3LAye3LxFcHg0UePmbSA.png"
        title="https://hackernoon.com/hn-images/1*oU3LAye3LxFcHg0UePmbSA.png" /></p>
<p>​																																														Source: <a href="https://hackernoon.com/" target="_blank" rel="noopener noreffer">hackernoon</a></p>
<p>The first steps were to understand the main problem, get familiar with the structure of the data and decide what features we need. This is a <strong>Time-Series prediction</strong>, so we need to be careful about the sequence of the data. In any modeling process, the data that goes into a model plays a big role in ensuring accurate results. Therefore, the relevant features that helped achieve the objective were defined and an initial feature set was selected.</p>
<p>Following this, some noisy and missing data was removed. We had access to data on restaurant reservations, but the dataset was incomplete and not of much use to us. Thus we didn&rsquo;t take this factor into account. Too many missing values might lead to a worse result even if it&rsquo;s a good predictor.</p>
<p>Some fields’ values were imputed - for example, those of extreme actual visitor numbers on a specific day. After the data engineering, the core modeling process was started. Different algorithms were implemented on the feature set, along with cyclical addition and removal of features depending on performance and complexity of the features and the model used.</p>
<p><img src="https://i.loli.net/2019/12/01/buTGivKW5jAJwk7.png" alt="47651575174054_.pic.jpg" style="zoom: 67%;" /></p>
<h2 id="2-feature-engineering">2. Feature Engineering</h2>
<p>Because this is a time series problem, t&rsquo;s better to take feature selection as the first step. Feature selection enables the machine learning algorithm to train faster. It reduces the complexity of a model and makes it easier to interpret and reduces the risk of overfitting. It also improves the accuracy of a model if the right subset is chosen.</p>
<h3 id="time-series-features">Time Series Features</h3>
<p>In order to take advantage of the date information, we extract year/month/day/weekday from the column <code>visit_date</code> as our features.</p>
<ul>
<li>
<p><strong>Visit date</strong> - original column in the data. The date visitor come to the restaurant. Used for mapping different data files</p>
</li>
<li>
<p><strong>Day of week</strong> - day of the week. Use numeric value to represent. If the day is weekend, it might have more traffic than normal weekdays.</p>
</li>
<li>
<p><strong>Month of the Year</strong> - different months also has different volume. This variable is kind of similar to season which showcase the seasonality of the time in a year</p>
</li>
<li>
<p><strong>Holiday Status</strong> - whether a day is holiday. This vairable can indicate the holiday flag. If it&rsquo;s holiday time, there might be higher traffic outside and restaurant might also have more number of visitors. Thus this shoud be a good predictor</p>
</li>
<li>
<p><strong>Next day holiday</strong> - whether the next day is holiday. Days around holiday might also play a role in attracting visitors to restaurants. If the next day is holiday, people may be tried and don&rsquo;t hand out in the previous</p>
</li>
<li>
<p><strong>Previous day holiday</strong> - Same to the above two predictors</p>
</li>
<li>
<p><strong>Consecutive Holidays</strong> - other than normal holiday flag data in the <code>data_info.csv</code>, we believe consective holidays and the length of days off-work also have a say in restaurant visiting patterns. For example, if the holiday is Friday, we will mark Friday, and the followed weekend with 3. Same goes when Monday is holiday and so on.</p>
</li>
<li>
<p><strong>Seasons</strong> - Japan has four distinct seasons: March to May is spring; June to August is summer; September to November is autumn; and December to February is winter. Each season has very different temperatures and climates which might affect the traffic.</p>
</li>
<li>
<p><strong>Prior Year Mapping</strong>
One obvious solution to predicting visitors would be to look at how many customers came the year before. For example, if we are predicting for Jan 10, we might want to look at Jan 10th of the prior year.
However, this is a slight problem here: what if Jan 10th of the previous year fell on a Saturday, but this year it falls on a Monday?  To adjust this, we instead will take the number of visitors from the matching <code>week of the year</code> &amp; the <code>day of the week</code> together.
After running our LightGBM model, this feature was in the top 5 in terms of importance.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">final</span><span class="p">[</span><span class="s1">&#39;prev_visitors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">final</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span>
    <span class="p">[</span><span class="n">final</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">week</span><span class="p">,</span>
     <span class="n">final</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">weekday</span><span class="p">])[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">()</span>
</code></pre></div></li>
<li>
<p><strong>Days since 25th</strong> (<strong>Paycheck Day. Yay!)</strong></p>
<p>The next feature calculates how many days it has been since the previous 25th of the month. The 25th is special because this is when most Japanese people receive their monthly paycheck <a href="http://www.japanvisa.com/news/japan-payroll-%e2%80%93-introduction" target="_blank" rel="noopener noreffer">Japan Visa</a></p>
<p>In a country like the US, this may not play too large of a role as people simply use a credit card. In Japan, however, people seem to be averse to debt and prefer cash over credit cards (<a href="https://blog.btrax.com/japanese-hold-as-many-credit-cards-as-americans-but-do-they-use-them/" target="_blank" rel="noopener noreffer">Business in Japan</a>).</p>
<p>After running our LightGBM model, this feature was in the top 5 in terms of importance.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">daysToPrev25th</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="n">TARGET_DATE</span> <span class="o">=</span> <span class="mi">25</span>
  <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;dayofmonth&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">25</span><span class="p">:</span> 	<span class="k">return</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;dayofmonth&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">TARGET_DATE</span>
    <span class="k">else</span><span class="p">:</span> 	<span class="k">return</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;daysinPrevmonth&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">TARGET_DATE</span> <span class="o">+</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;dayofmonth&#39;</span><span class="p">]</span>
  
<span class="n">air_visit</span><span class="p">[</span><span class="s2">&#34;dayofmonth&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">air_visit</span><span class="p">[</span><span class="s2">&#34;visit_date&#34;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">day</span>      
<span class="n">air_visit</span><span class="p">[</span><span class="s2">&#34;daysinPrevmonth&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">air_visit</span><span class="p">[</span><span class="s2">&#34;visit_date&#34;</span><span class="p">]</span> <span class="o">-</span> <span class="n">pd</span><span class="o">.</span><span class="n">DateOffset</span><span class="p">(</span><span class="n">months</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">daysinmonth</span>
<span class="n">air_visit</span><span class="p">[</span><span class="s2">&#34;daysToPrev25th&#34;</span><span class="p">]</span> <span class="o">=</span> <span class="n">air_visit</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span><span class="n">daysToPrev25th</span><span class="p">(</span><span class="n">row</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></li>
</ul>
<h3 id="visit-features">Visit Features</h3>
<p>Note that <code>visitors</code> does not exist in test set. Features such as locations and genres are categorical attributes and many missing values are involved. In this case, we need to create features on <code>visitors</code> , which will rely on the number of <code>visitors</code> to calculate. Therefore, we can feed visitors related features into our models to provide clues regarding stores.</p>
<p>Here, we calculate min, max, median, mean, and the number of times each store has been visited per each day of the week. The following code might look complicated but we are using the aggregate method of &ldquo;group by&rdquo; essentially.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">visitor_features</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">visitor_data</span><span class="p">):</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="n">visitor_data</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">,</span> <span class="s1">&#39;dow&#39;</span><span class="p">],</span> <span class="n">as_index</span><span class="o">=</span><span class="bp">False</span><span class="p">)[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;visitors&#39;</span><span class="p">:</span> <span class="s1">&#39;min_visitors&#39;</span><span class="p">})</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">tmp</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">,</span> <span class="s1">&#39;dow&#39;</span><span class="p">])</span>
<span class="n">visitor_data</span><span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">visitor_features</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">visitor_data</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">visitor_features</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">visitor_data</span><span class="p">)</span>
</code></pre></div><ul>
<li><strong>max visitors</strong>: maximum number of visitors for each store for a specific weekday</li>
<li><strong>min visitors</strong>: minimum number of visitors for each store for a specific weekday</li>
<li><strong>average visitors</strong>: average number of visitors for each store for a specific weekday</li>
<li>count observations: number of observations for each store in a specific weekday. We take this feature into consideration because a number of stores don&rsquo;t open to business everyday</li>
<li><strong>exponential moving average</strong>: the most recent data is weighted to have more of an impact</li>
</ul>
<h3 id="geographical-features">Geographical Features</h3>
<p>Geographic features were not exactly straightforward to deal with. We had to do a bit of munging and pulling external data to determine the impact that locations had.</p>
<ul>
<li>
<p><strong>City</strong> - We weren&rsquo;t provided with columns such as <code>region</code>, <code>city</code>, <code>neighorhood</code>, etc. Instead, we had one column that included 5 levels of detail. Our dataset was in English, but the cities retained their original Japanese symbols. We had longitude and latitude data from 2 different systems to 6 decimal places, so the numbers sometimes did not match up exactly. So we need to split the column and select the information we need.</p>
</li>
<li>
<p><strong>Population and Density</strong> - To go along with this, we have also added the population for each of the cities. This information comes from both <a href="https://simplemaps.com/data/jp-cities" target="_blank" rel="noopener noreffer">Simple Maps</a> and verified with <a href="https://en.wikipedia.org/wiki/List_of_cities_in_Japan" target="_blank" rel="noopener noreffer">Wikipedia</a>.
This is the dataset that we combined with our training set. We made sure that every city was included and that there were no missing values.
<em>Population is in millions, population density is in thousands.</em></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cities</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Tokyo-to&#39;</span><span class="p">,</span><span class="s1">&#39;Osaka-fu&#39;</span><span class="p">,</span><span class="s1">&#39;Fukuoka-ken&#39;</span><span class="p">,</span><span class="s1">&#39;Hyogo-ken&#39;</span><span class="p">,</span>
          <span class="s1">&#39;Hokkaido&#39;</span><span class="p">,</span><span class="s1">&#39;Hiroshima-ken&#39;</span><span class="p">,</span><span class="s1">&#39;Shizuoka-ken&#39;</span><span class="p">,</span>
          <span class="s1">&#39;Miyagi-ken&#39;</span><span class="p">,</span><span class="s1">&#39;Niigata-ken&#39;</span><span class="p">,</span><span class="s1">&#39;Osaka&#39;</span><span class="p">,</span><span class="s1">&#39;Kanagawa-ken&#39;</span><span class="p">,</span> <span class="s1">&#39;Saitama-ken&#39;</span><span class="p">]</span>
<span class="n">population</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.7</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">8.6</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span><span class="mf">3.7</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="o">.</span><span class="mi">8</span><span class="p">,</span> <span class="mf">2.6</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">]</span>
<span class="n">density</span> <span class="o">=</span> <span class="p">[</span><span class="mf">11.9</span><span class="p">,</span> <span class="mf">5.4</span><span class="p">,</span> <span class="mf">13.9</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">8.5</span><span class="p">,</span><span class="mf">2.7</span><span class="p">,</span> <span class="o">.</span><span class="mi">7</span><span class="p">,</span> <span class="mf">11.9</span><span class="p">,</span> <span class="mf">4.4</span><span class="p">]</span>

<span class="n">pop</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">cities</span><span class="p">,</span> <span class="n">population</span><span class="p">,</span> <span class="n">density</span><span class="p">)),</span>
            <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cities&#39;</span><span class="p">,</span><span class="s1">&#39;population&#39;</span><span class="p">,</span> <span class="s1">&#39;density&#39;</span><span class="p">])</span>
</code></pre></div></li>
<li>
<p><strong>Restaurant Types</strong> - this information contains which food type the restaurant is selling. We are provided with restaurant types for every store in our data, but the labels are not consistent. In order to gain more meaningful data from the types of restaurants we are provided, we convert the many specific labels into more general labels that capture the restaurant type.
After looking at the plot below, we are doubtful that restaurant type plays much of a role for the restaurants we are predicting. It doesn&rsquo;t really seem like there is much of a relationship between restaurant type and expected visitors.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Quick example</span>
<span class="n">all_stores</span><span class="p">[</span><span class="s1">&#39;Food_Type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">all_stores</span><span class="p">[</span><span class="s1">&#39;Food_Type&#39;</span><span class="p">]</span>
     <span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">((</span><span class="s1">&#39;Izakaya&#39;</span><span class="p">),</span><span class="s1">&#39;Izakaya&#39;</span><span class="p">,</span><span class="n">all_stores</span><span class="p">[</span><span class="s1">&#39;Food_Type&#39;</span><span class="p">])</span>
</code></pre></div></li>
</ul>
<h3 id="data-cleaning">Data Cleaning</h3>
<h4 id="outliers">Outliers</h4>
<p>As we can see, the number of visitors is highly left skewed and the max number reached 877 which seems unreasonable. These values might be outliers.</p>
<p>We simply define outliers using the following rules:</p>
<ul>
<li>Data point that falls outside of 1.5 times of an interquartile range above the 3rd quartile and below the 1st quartile</li>
<li>Data point that falls outside of 3 standard deviations.</li>
</ul>
<p><img src="https://i.loli.net/2019/12/01/buTGivKW5jAJwk7.png" alt="47651575174054_.pic.jpg" style="zoom: 67%;" /></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">q1</span><span class="p">,</span> <span class="n">q3</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">visitors</span><span class="p">,[</span><span class="mi">25</span><span class="p">,</span><span class="mi">75</span><span class="p">])</span>
<span class="n">iqr</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">-</span> <span class="n">q1</span>
<span class="n">lower_bound</span> <span class="o">=</span> <span class="n">q1</span> <span class="o">-</span><span class="p">(</span><span class="mf">1.5</span> <span class="o">*</span> <span class="n">iqr</span><span class="p">)</span>
<span class="n">upper_bound</span> <span class="o">=</span> <span class="n">q3</span> <span class="o">+</span><span class="p">(</span><span class="mf">1.5</span> <span class="o">*</span> <span class="n">iqr</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="n">visitors</span> <span class="o">&gt;</span> <span class="n">upper_bound</span> <span class="p">,</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">upper_bound</span>
<span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="n">visitors</span> <span class="o">&lt;</span> <span class="n">lower_bound</span> <span class="p">,</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lower_bound</span>
</code></pre></div><p>After this process we will get a nicer distribution.</p>
<p><img src="https://i.imgur.com/yg0MqGh.jpg" style="zoom:67%;" /></p>
<h2 id="3-modeling">3. Modeling</h2>
<p>Given the Time Series nature of our prediction exercise, we started by implementing the model ARIMA, short for Auto Regressive Integrated Moving Average, which is a model that explains a given time series based on its own past values, i.e. its own lags and the lagged forecast errors, so that equation can be used to forecast future values. But as we can see from this explanation, ARIMA model doesn&rsquo;t take into consideration external factors to forecast the number of visitors.</p>
<p>We then implemented another famous model for Time series which is Facebook Prophet, which is a procedure based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. However, this model works best with time series that have strong seasonal effects and several seasons of historical data, which is not the case in our prediction exercise.</p>
<p>That&rsquo;s when we shifted our approach to Light GBM, which is a gradient boosting framework that uses tree based learning algorithms. The advantage of this approach is that it doesn&rsquo;t need any statistical assumptions in the backend. Besides, it determines which features have the highest discriminative powers,  which enables us to give valuable insights to the restaurant owners.</p>
<h3 id="arima">ARIMA</h3>
<div class="highlight"><pre class="chroma"><code class="language-R" data-lang="R"><span class="c1"># forecasting - register cores for parallel processing</span>
<span class="nf">registerDoMC</span><span class="p">(</span><span class="nf">detectCores</span><span class="p">()</span><span class="m">-1</span><span class="p">)</span>
<span class="n">fcst_matrix</span> <span class="o">&lt;-</span> <span class="nf">foreach</span><span class="p">(</span><span class="n">i</span><span class="o">=</span><span class="m">1</span><span class="o">:</span><span class="nf">nrow</span><span class="p">(</span><span class="n">train_ts</span><span class="p">),</span><span class="n">.combine</span><span class="o">=</span><span class="n">rbind</span><span class="p">,</span> <span class="n">.packages</span><span class="o">=</span><span class="nf">c</span><span class="p">(</span><span class="s">&#34;forecast&#34;</span><span class="p">))</span> <span class="o">%dopar%</span> <span class="p">{</span>
    <span class="n">fcst_ets</span> <span class="o">&lt;-</span> <span class="nf">forecast</span><span class="p">(</span><span class="nf">ets</span><span class="p">(</span><span class="n">train_ts[i</span><span class="p">,</span><span class="n">]</span><span class="p">),</span><span class="n">h</span><span class="o">=</span><span class="n">fcst_intv</span><span class="p">)</span><span class="o">$</span><span class="n">mean</span>
    <span class="n">fcst_nnet</span> <span class="o">&lt;-</span> <span class="nf">forecast</span><span class="p">(</span><span class="nf">nnetar</span><span class="p">(</span><span class="n">train_ts[i</span><span class="p">,</span><span class="n">]</span><span class="p">),</span><span class="n">h</span><span class="o">=</span><span class="n">fcst_intv</span><span class="p">)</span><span class="o">$</span><span class="n">mean</span>
    <span class="n">fcst_arima</span> <span class="o">&lt;-</span> <span class="nf">forecast</span><span class="p">(</span><span class="nf">auto.arima</span><span class="p">(</span><span class="n">train_ts[i</span><span class="p">,</span><span class="n">]</span><span class="p">),</span><span class="n">h</span><span class="o">=</span><span class="n">fcst_intv</span><span class="p">)</span><span class="o">$</span><span class="n">mean</span>
    <span class="n">fcst_ses</span> <span class="o">&lt;-</span> <span class="nf">forecast</span><span class="p">(</span><span class="nf">HoltWinters</span><span class="p">(</span><span class="n">train_ts[i</span><span class="p">,</span><span class="n">]</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="kc">FALSE</span><span class="p">),</span><span class="n">h</span><span class="o">=</span><span class="n">fcst_intv</span><span class="p">)</span><span class="o">$</span><span class="n">mean</span>
    <span class="n">fcst_matrix</span> <span class="o">&lt;-</span> <span class="nf">rbind</span><span class="p">(</span><span class="n">fcst_ets</span><span class="p">,</span> <span class="n">fcst_nnet</span><span class="p">,</span> <span class="n">fcst_arima</span><span class="p">,</span> <span class="n">fcst_ses</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># post-processing the forecast table</span>
<span class="n">fcst_matrix_mix</span> <span class="o">&lt;-</span> <span class="nf">aggregate</span><span class="p">(</span><span class="n">fcst_matrix</span><span class="p">,</span><span class="nf">list</span><span class="p">(</span><span class="nf">rep</span><span class="p">(</span><span class="m">1</span><span class="o">:</span><span class="p">(</span><span class="nf">nrow</span><span class="p">(</span><span class="n">fcst_matrix</span><span class="p">)</span><span class="o">/</span><span class="m">4</span><span class="p">),</span><span class="n">each</span><span class="o">=</span><span class="m">4</span><span class="p">)),</span><span class="n">mean</span><span class="p">)</span><span class="n">[</span><span class="m">-1</span><span class="n">]</span>
<span class="n">fcst_matrix_mix[fcst_matrix_mix</span> <span class="o">&lt;</span> <span class="m">0</span><span class="n">]</span> <span class="o">&lt;-</span> <span class="m">0</span>
<span class="nf">colnames</span><span class="p">(</span><span class="n">fcst_matrix_mix</span><span class="p">)</span> <span class="o">&lt;-</span> <span class="nf">as.character</span><span class="p">(</span>
  <span class="nf">seq</span><span class="p">(</span><span class="n">from</span> <span class="o">=</span> <span class="nf">as.Date</span><span class="p">(</span><span class="s">&#34;2017-04-23&#34;</span><span class="p">),</span> <span class="n">to</span> <span class="o">=</span> <span class="nf">as.Date</span><span class="p">(</span><span class="s">&#34;2017-05-31&#34;</span><span class="p">),</span> <span class="n">by</span> <span class="o">=</span> <span class="s">&#39;day&#39;</span><span class="p">))</span>
<span class="n">fcst_df</span> <span class="o">&lt;-</span> <span class="nf">as.data.frame</span><span class="p">(</span><span class="nf">cbind</span><span class="p">(</span><span class="n">train_wide[</span><span class="p">,</span> <span class="m">1</span><span class="n">]</span><span class="p">,</span> <span class="n">fcst_matrix_mix</span><span class="p">))</span>
<span class="nf">colnames</span><span class="p">(</span><span class="n">fcst_df</span><span class="p">)</span><span class="n">[1]</span> <span class="o">&lt;-</span> <span class="s">&#34;air_store_id&#34;</span>

<span class="c1"># melt the forecast data frame from wide to long format for final submission</span>
<span class="n">fcst_df_long</span> <span class="o">&lt;-</span> <span class="nf">melt</span><span class="p">(</span>
  <span class="n">fcst_df</span><span class="p">,</span> <span class="n">id</span> <span class="o">=</span> <span class="s">&#39;air_store_id&#39;</span><span class="p">,</span> <span class="n">variable.name</span> <span class="o">=</span> <span class="s">&#34;fcst_date&#34;</span><span class="p">,</span> <span class="n">value.name</span> <span class="o">=</span> <span class="s">&#39;visitors&#39;</span><span class="p">)</span>
<span class="n">fcst_df_long</span><span class="o">$</span><span class="n">air_store_id</span> <span class="o">&lt;-</span> <span class="nf">as.character</span><span class="p">(</span><span class="n">fcst_df_long</span><span class="o">$</span><span class="n">air_store_id</span><span class="p">)</span>
<span class="n">fcst_df_long</span><span class="o">$</span><span class="n">fcst_date</span> <span class="o">&lt;-</span> <span class="nf">as.Date</span><span class="p">(</span><span class="nf">parse_date_time</span><span class="p">(</span><span class="n">fcst_df_long</span><span class="o">$</span><span class="n">fcst_date</span><span class="p">,</span><span class="s">&#39;%y-%m-%d&#39;</span><span class="p">))</span>
<span class="n">fcst_df_long</span><span class="o">$</span><span class="n">visitors</span> <span class="o">&lt;-</span> <span class="nf">as.numeric</span><span class="p">(</span><span class="n">fcst_df_long</span><span class="o">$</span><span class="n">visitors</span><span class="p">)</span>
</code></pre></div><h3 id="prophet">Prophet</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Prediction</span>
<span class="kn">from</span> <span class="nn">fbprophet</span> <span class="kn">import</span> <span class="n">Prophet</span>
<span class="c1"># This is used for suppressing prophet info messages.</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;fbprophet.forecaster&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">propagate</span> <span class="o">=</span> <span class="bp">False</span>

<span class="n">number_of_stores</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;store_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span>
<span class="n">date_range</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s1">&#39;2016-07-01&#39;</span><span class="p">),</span>
                           <span class="n">end</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s1">&#39;2017-04-22&#39;</span><span class="p">))</span>
<span class="n">forecast_days</span> <span class="o">=</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s1">&#39;2017-05-31&#39;</span><span class="p">)</span><span class="o">-</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s1">&#39;2017-04-22&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">days</span>

<span class="k">for</span> <span class="n">cnt</span><span class="p">,</span> <span class="n">store_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;store_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()):</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Predicting </span><span class="si">%d</span><span class="s1"> of </span><span class="si">%d</span><span class="s1">.&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">cnt</span><span class="p">,</span> <span class="n">number_of_stores</span><span class="p">),</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">visitor_data</span><span class="p">[</span><span class="n">visitor_data</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">store_id</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">,</span> <span class="s1">&#39;visitors&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;visit_date&#39;</span><span class="p">)</span>
    <span class="c1"># Ensure we have full range of dates.</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">date_range</span><span class="p">)</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ds&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">]</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">Prophet</span><span class="p">(</span><span class="n">holidays</span><span class="o">=</span><span class="n">df_holidays</span><span class="p">)</span>
    <span class="n">m</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">future</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">make_future_dataframe</span><span class="p">(</span><span class="n">forecast_days</span><span class="p">)</span>
    <span class="n">forecast</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">future</span><span class="p">)</span>
    <span class="n">forecast</span> <span class="o">=</span> <span class="n">forecast</span><span class="p">[[</span><span class="s1">&#39;ds&#39;</span><span class="p">,</span> <span class="s1">&#39;yhat&#39;</span><span class="p">]]</span>
    <span class="n">forecast</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">,</span> <span class="s1">&#39;visitors&#39;</span><span class="p">]</span>
    <span class="n">forecast</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">forecast</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">store_id</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)))</span>
    <span class="n">forecast</span> <span class="o">=</span> <span class="n">forecast</span><span class="o">.</span><span class="n">set_index</span><span class="p">(</span><span class="s1">&#39;id&#39;</span><span class="p">)</span>
    <span class="n">test</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">forecast</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">Done.&#39;</span><span class="p">)</span>
</code></pre></div><h3 id="lightgbm">LightGBM</h3>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1">#import lightgbm as lgbm</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">lgbm</span><span class="o">.</span><span class="n">LGBMRegressor</span><span class="p">(</span>
    <span class="n">objective</span><span class="o">=</span><span class="s1">&#39;regression&#39;</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">num_leaves</span><span class="o">=</span><span class="mi">5</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.007</span><span class="p">,</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">30000</span><span class="p">,</span>
    <span class="n">min_child_samples</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span>
    <span class="n">subsample</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">colsample_bytree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">reg_alpha</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">reg_lambda</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">10e6</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">folds</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span> <span class="n">folds</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">val</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">folds</span>

<span class="n">sub</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span>
<span class="n">sub</span><span class="p">[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="n">feature_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">train_x</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">fit_idx</span><span class="p">,</span> <span class="n">val_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)):</span>

    <span class="n">X_fit</span> <span class="o">=</span> <span class="n">train_x</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">fit_idx</span><span class="p">]</span>
    <span class="n">y_fit</span> <span class="o">=</span> <span class="n">train_y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">fit_idx</span><span class="p">]</span>
    <span class="n">X_val</span> <span class="o">=</span> <span class="n">train_x</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>
    <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]</span>

    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">X_fit</span><span class="p">,</span>
        <span class="n">y_fit</span><span class="p">,</span>
        <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_fit</span><span class="p">,</span> <span class="n">y_fit</span><span class="p">),</span> <span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)],</span>
        <span class="n">eval_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;fit&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">),</span>
        <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span>
        <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
        <span class="n">feature_name</span><span class="o">=</span><span class="n">X_fit</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
        <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span>
    <span class="p">)</span>

    <span class="n">val</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">best_score_</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">][</span><span class="s1">&#39;l2&#39;</span><span class="p">])</span>
    <span class="n">sub</span><span class="p">[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">num_iteration</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">best_iteration_</span><span class="p">)</span>
    <span class="n">feature_importances</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span>

    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;Fold {} RMSLE: {:.5f}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">val_scores</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="n">sub</span><span class="p">[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span> <span class="o">/=</span> <span class="n">n_splits</span>
<span class="n">sub</span><span class="p">[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">sub</span><span class="p">[</span><span class="s1">&#39;visitors&#39;</span><span class="p">])</span>

<span class="n">val_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">val_scores</span><span class="p">)</span>
<span class="n">val_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">val_scores</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Local RMSLE: {:.5f} (±{:.5f})&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val_mean</span><span class="p">,</span> <span class="n">val_std</span><span class="p">))</span>
</code></pre></div><h3 id="lstm-seq2seq--encoderdecoder">LSTM seq2seq + Encoder/Decoder</h3>
<p>Note that we have included all of the details below for this model in particular because this is our final model. Additionally, this model is best suited for this problem.</p>
<h4 id="motivation"><strong>Motivation</strong></h4>
<p>LSTM is a great solution for relatively short sequences, up to 100-300 items. On longer sequences LSTM still works, but can gradually forget information from the oldest items. In our dataset, the timeseries is up to 478 days long, so we decided to implement encoder and decoder to &ldquo;strengthen&rdquo; LSTM memory.</p>
<p>We are using the encoder and decoder structure in the <strong>Sequence-to-sequence learning (Seq2Seq)</strong>  concept, which is about training models to convert sequences from one domain (e.g. sentences in English) to sequences in another domain (e.g. the same sentences translated to French).</p>
<p>We used one LSTM RNN layer as &ldquo;<strong>encoder</strong>&quot;: it processes the input sequence and returns its own internal state. Note  that we discard the outputs of the encoder RNN, only recovering the state. This state will serve as the &ldquo;context&rdquo;, or &ldquo;conditioning&rdquo;, of the decoder in the next step.</p>
<p>And then we used another RNN layer with 2 hidden LSTM model acts as &ldquo;<strong>decoder</strong>&quot;: it is trained to predict the next characters of the target sequence, given previous characters of the target sequence. Specifically, it is trained to turn the target sequences into the same sequences but offset by one timestep in the future, a training process called &ldquo;teacher forcing&rdquo; in this context. Importantly, the encoder uses as initial state the state vectors from the encoder, which is how the decoder obtains information about what it is supposed to generate.</p>
<h4 id="data-preparation"><strong>Data Preparation</strong></h4>
<p><strong>1) Basic tidying of the training and test table</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Drop unnecessary columns</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span> <span class="s1">&#39;population&#39;</span><span class="p">,</span> <span class="s1">&#39;reserve_visitors&#39;</span><span class="p">,</span> <span class="s1">&#39;days_diff&#39;</span><span class="p">,</span> <span class="s1">&#39;day&#39;</span><span class="p">,</span> <span class="s1">&#39;season&#39;</span><span class="p">])</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;population&#39;</span><span class="p">,</span> <span class="s1">&#39;reserve_visitors&#39;</span><span class="p">,</span><span class="s1">&#39;days_diff&#39;</span><span class="p">,</span> <span class="s1">&#39;day&#39;</span><span class="p">,</span> <span class="s1">&#39;season&#39;</span><span class="p">])</span>
<span class="c1"># Refine column names</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;visitors_x&#39;</span><span class="p">:</span> <span class="s1">&#39;visitors&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;day_of_week_y&#39;</span><span class="p">:</span> <span class="s1">&#39;day_of_week&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;month_y&#39;</span><span class="p">:</span> <span class="s1">&#39;month&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;longitude_y&#39;</span><span class="p">:</span> <span class="s1">&#39;longitude&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;latitude_y&#39;</span><span class="p">:</span> <span class="s1">&#39;latitude&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;latitude_y&#39;</span><span class="p">:</span> <span class="s1">&#39;latitude&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;longitude_y&#39;</span><span class="p">:</span> <span class="s1">&#39;longitude&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;month_y&#39;</span><span class="p">:</span> <span class="s1">&#39;month&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">rename</span><span class="p">({</span><span class="s1">&#39;day_of_week_y&#39;</span><span class="p">:</span> <span class="s1">&#39;day_of_week&#39;</span><span class="p">},</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="c1"># Clean unnecessary columns</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="o">~</span><span class="n">train_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;^Unnamed&#39;</span><span class="p">)]</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="o">~</span><span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;^Unnamed&#39;</span><span class="p">)]</span>
<span class="c1"># Fill the cells of missing values with -1</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div><p><strong>2) Encode categorical columns</strong></p>
<p>There are several categorical columns in the dataset, which are  &lsquo;Food_Type&rsquo;, &lsquo;day_of_week&rsquo;, &lsquo;air_store_id&rsquo; that needs to be transferred. One-hot encoding may provide better result, but we applied labels encoding to avoid high dimensional feature space.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># Weekday</span>
<span class="n">le_weekday</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_weekday</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;day_of_week&#39;</span><span class="p">])</span>
<span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;day_of_week&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_weekday</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;day_of_week&#39;</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;day_of_week&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_weekday</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;day_of_week&#39;</span><span class="p">])</span>

<span class="c1"># id</span>
<span class="n">le_id</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_id</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">])</span>
<span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_id</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_id</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">])</span>

<span class="c1"># food type</span>
<span class="n">le_ftype</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">le_ftype</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Food_Type&#39;</span><span class="p">])</span>
<span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Food_Type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_ftype</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Food_Type&#39;</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;Food_Type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">le_ftype</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;Food_Type&#39;</span><span class="p">])</span>

</code></pre></div><p><strong>3) Simultaneous transformation of Train and test sets</strong></p>
<p>Considering the input data structure the LSTM RNN model needed, we filled up all the dates within the whole time span (2016-01-01 ~ 2017-05-31) for each stores with number of visitors as 0 on those dates, and the time-independent features (food types, longitude, latitude, etc) are &ldquo;stretched&rdquo; to timeseries length.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># combine train and test sets</span>
<span class="n">X_all</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="c1"># date table (includes all dates for training and test period)</span>
<span class="n">dates</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="n">X_all</span><span class="o">.</span><span class="n">visit_date</span><span class="o">.</span><span class="n">min</span><span class="p">()),</span>
                  <span class="n">np</span><span class="o">.</span><span class="n">datetime64</span><span class="p">(</span><span class="n">X_all</span><span class="o">.</span><span class="n">visit_date</span><span class="o">.</span><span class="n">max</span><span class="p">())</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                  <span class="n">datetime</span><span class="o">.</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">X_all</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
<span class="n">dates_all</span> <span class="o">=</span> <span class="n">dates</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">)</span>
<span class="n">ids_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">ids</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dates</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">df_all</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&#34;air_store_id&#34;</span><span class="p">:</span> <span class="n">ids_all</span><span class="p">,</span> <span class="s2">&#34;visit_date&#34;</span><span class="p">:</span> <span class="n">dates_all</span><span class="p">})</span>
<span class="n">df_all</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_all</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)[:</span><span class="mi">10</span><span class="p">])</span>

<span class="c1"># create copy of X_all with data relevant to &#39;visit_date&#39;</span>
<span class="n">X_dates</span> <span class="o">=</span> <span class="n">X_all</span><span class="p">[[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">,</span> <span class="s1">&#39;year&#39;</span><span class="p">,</span><span class="s1">&#39;month&#39;</span><span class="p">,</span><span class="s1">&#39;week&#39;</span><span class="p">,</span>\
                 <span class="s1">&#39;is_holiday&#39;</span><span class="p">,</span><span class="s1">&#39;next_day&#39;</span><span class="p">,</span><span class="s1">&#39;prev_day&#39;</span><span class="p">,</span>\
                 <span class="s1">&#39;daysToPrev25th&#39;</span><span class="p">,</span><span class="s1">&#39;day_of_week&#39;</span><span class="p">,</span><span class="s1">&#39;Consecutive_holidays&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># remove duplicates to avoid memory issues</span>
<span class="n">X_dates</span> <span class="o">=</span> <span class="n">X_dates</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="s1">&#39;visit_date&#39;</span><span class="p">)</span>

<span class="c1"># merge dataframe that represents all dates per each restaurant with information about each date</span>
<span class="n">df_to_reshape</span> <span class="o">=</span> <span class="n">df_all</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X_dates</span><span class="p">,</span>
                             <span class="n">how</span> <span class="o">=</span> <span class="s2">&#34;left&#34;</span><span class="p">,</span>
                             <span class="n">left_on</span> <span class="o">=</span> <span class="s1">&#39;visit_date&#39;</span><span class="p">,</span>
                             <span class="n">right_on</span> <span class="o">=</span> <span class="s1">&#39;visit_date&#39;</span><span class="p">)</span>

<span class="c1"># create copy of X_all with data relevant to &#39;air_store_id&#39;</span>
<span class="n">X_stores</span> <span class="o">=</span> <span class="n">X_all</span><span class="p">[[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">,</span> <span class="s1">&#39;Food_Type&#39;</span><span class="p">,</span> <span class="s1">&#39;latitude&#39;</span><span class="p">,</span><span class="s1">&#39;longitude&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>       

<span class="c1"># remove duplicates to avoid memory issues</span>
<span class="n">X_stores</span> <span class="o">=</span> <span class="n">X_stores</span><span class="o">.</span><span class="n">drop_duplicates</span><span class="p">(</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">)</span>

<span class="c1"># merge dataframe that represents all dates per each restaurant with information about each restaurant</span>
<span class="n">df_to_reshape</span> <span class="o">=</span> <span class="n">df_to_reshape</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X_stores</span><span class="p">,</span>
                                    <span class="n">how</span> <span class="o">=</span> <span class="s2">&#34;left&#34;</span><span class="p">,</span>
                                    <span class="n">left_on</span> <span class="o">=</span> <span class="s1">&#39;air_store_id&#39;</span><span class="p">,</span>
                                    <span class="n">right_on</span> <span class="o">=</span> <span class="s1">&#39;air_store_id&#39;</span><span class="p">)</span>
<span class="c1"># merge dataframe that represents all dates per each restaurant with inf. about each restaurant per specific date</span>
<span class="n">df_to_reshape</span> <span class="o">=</span> <span class="n">df_to_reshape</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">X_all</span><span class="p">[[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">,</span> <span class="s1">&#39;visit_date&#39;</span><span class="p">,</span>\
                                           <span class="s1">&#39;prev_visitors&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_visitors&#39;</span><span class="p">,</span>\
                                       <span class="s1">&#39;median_visitors&#39;</span><span class="p">,</span> <span class="s1">&#39;max_visitors&#39;</span><span class="p">,</span> \
                                           <span class="s1">&#39;min_visitors&#39;</span><span class="p">,</span><span class="s1">&#39;count_observations&#39;</span>\
                                           <span class="p">,</span><span class="s1">&#39;visitors&#39;</span><span class="p">]],</span>
                                    <span class="n">how</span> <span class="o">=</span> <span class="s2">&#34;left&#34;</span><span class="p">,</span>
                                    <span class="n">left_on</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">,</span> <span class="s1">&#39;visit_date&#39;</span><span class="p">],</span>
                                    <span class="n">right_on</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">,</span> <span class="s1">&#39;visit_date&#39;</span><span class="p">])</span>

<span class="c1"># separate &#39;visitors&#39; into output array</span>
<span class="n">Y_lstm_df</span> <span class="o">=</span> <span class="n">df_to_reshape</span><span class="p">[[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">,</span> <span class="s1">&#39;air_store_id&#39;</span><span class="p">,</span> <span class="s1">&#39;visitors&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># take log(y+1)</span>
<span class="n">Y_lstm_df</span><span class="p">[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">Y_lstm_df</span><span class="p">[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>

<span class="c1"># add flag for days when a restaurant was closed</span>
<span class="n">df_to_reshape</span><span class="p">[</span><span class="s1">&#39;closed_flag&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df_to_reshape</span><span class="p">[</span><span class="s1">&#39;visitors&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span> <span class="o">&amp;</span>
                                        <span class="n">df_to_reshape</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># drop &#39;visitors&#39; and from dataset</span>
<span class="n">df_to_reshape</span> <span class="o">=</span> <span class="n">df_to_reshape</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;visitors&#39;</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># fill in NaN values</span>
<span class="n">df_to_reshape</span> <span class="o">=</span> <span class="n">df_to_reshape</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># list of df_to_reshape columns without &#39;air_store_id&#39; and &#39;visit_date&#39;</span>
<span class="n">columns_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">df_to_reshape</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:])]</span>

</code></pre></div><p><strong>4) Normalize all numerical values</strong></p>
<p>We bounded all numerical values between -1 and 1. To avoid data leakage &lsquo;fit&rsquo; should be made on train data and &lsquo;transform&rsquo; on train and test data in this case all data in test set is taken from train set, thus fit/transform on all data.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">scaler</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">df_to_reshape</span><span class="p">[</span><span class="n">columns_list</span><span class="p">])</span>
<span class="n">df_to_reshape</span><span class="p">[</span><span class="n">columns_list</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">df_to_reshape</span><span class="p">[</span><span class="n">columns_list</span><span class="p">])</span>
</code></pre></div><p><strong>5) Reshape data structure for Neural Network and Encoder/Decoder</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># reshape X into (samples, timesteps, features)</span>
<span class="n">X_all_lstm</span> <span class="o">=</span> <span class="n">df_to_reshape</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ids</span><span class="p">),</span>
                                                <span class="nb">len</span><span class="p">(</span><span class="n">dates</span><span class="p">),</span>
                                                <span class="n">df_to_reshape</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># isolate output for train set and reshape it for time series</span>
<span class="n">Y_lstm_df</span> <span class="o">=</span> <span class="n">Y_lstm_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">Y_lstm_df</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span> <span class="o">&amp;</span>
                          <span class="n">Y_lstm_df</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">),]</span>
<span class="n">Y_lstm</span> <span class="o">=</span> <span class="n">Y_lstm_df</span><span class="o">.</span><span class="n">values</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()),</span>
                                       <span class="nb">len</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()),</span>
                                       <span class="mi">1</span><span class="p">)</span>
<span class="c1"># test dates</span>
<span class="n">n_test_dates</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>

</code></pre></div><p><strong>6) Training and validation split</strong></p>
<p>There are two ways to split timeseries into training and validation datasets:</p>
<ol>
<li>Walk-forward split. This is not actually a split: we train on full dataset and validate on full dataset, using different timeframes. Timeframe for validation is shifted forward by one prediction interval relative to timeframe for training.</li>
<li>Side-by-side split. This is traditional split model for mainstream machine learning. Dataset splits into independent parts, one part used strictly for training and another part used strictly for validation.</li>
</ol>
<p>Walk-forward is preferable, because it directly relates to the competition goal: predict future values using historical values. But this split consumes data points at the end of timeseries, thus making hard to train model to precisely predict the future.</p>
<p>We used validation (with walk-forward split) only for model tuning. Final model to predict future values was trained in blind mode, without any validation.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># make additional features for number of visitors in t-1, t-2, ... t-7</span>
<span class="n">t_minus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">Y_lstm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">Y_lstm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="mi">1</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">):</span>
    <span class="n">temp</span> <span class="o">=</span> <span class="n">Y_lstm</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">temp</span><span class="p">[:,</span><span class="n">i</span><span class="p">:,:]</span> <span class="o">=</span> <span class="n">Y_lstm</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">i</span><span class="p">,:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">t_minus</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">t_minus</span><span class="p">[</span><span class="o">...</span><span class="p">],</span> <span class="n">temp</span><span class="p">[</span><span class="o">...</span><span class="p">]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">t_minus</span> <span class="o">=</span> <span class="n">t_minus</span><span class="p">[:,:,</span><span class="mi">1</span><span class="p">:]</span>
<span class="k">print</span> <span class="p">(</span><span class="s2">&#34;t_minus shape&#34;</span><span class="p">,</span> <span class="n">t_minus</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="c1"># split X_all into training and test data</span>
<span class="n">X_lstm</span> <span class="o">=</span> <span class="n">X_all_lstm</span><span class="p">[:,:</span><span class="o">-</span><span class="n">n_test_dates</span><span class="p">,:]</span>
<span class="n">X_lstm_test</span> <span class="o">=</span> <span class="n">X_all_lstm</span><span class="p">[:,</span><span class="o">-</span><span class="n">n_test_dates</span><span class="p">:,:]</span>

<span class="c1"># add t-1, t-2 ... t-7 visitors to feature vector</span>
<span class="n">X_lstm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X_lstm</span><span class="p">[</span><span class="o">...</span><span class="p">],</span> <span class="n">t_minus</span><span class="p">[</span><span class="o">...</span><span class="p">]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># split training set into train and validation sets</span>
<span class="n">X_tr</span> <span class="o">=</span> <span class="n">X_lstm</span><span class="p">[:,</span><span class="mi">39</span><span class="p">:</span><span class="o">-</span><span class="mi">140</span><span class="p">,:]</span>
<span class="n">Y_tr</span> <span class="o">=</span> <span class="n">Y_lstm</span><span class="p">[:,</span><span class="mi">39</span><span class="p">:</span><span class="o">-</span><span class="mi">140</span><span class="p">,:]</span>

<span class="n">X_val</span> <span class="o">=</span> <span class="n">X_lstm</span><span class="p">[:,</span><span class="o">-</span><span class="mi">140</span><span class="p">:,:]</span>
<span class="n">Y_val</span> <span class="o">=</span> <span class="n">Y_lstm</span><span class="p">[:,</span><span class="o">-</span><span class="mi">140</span><span class="p">:,:]</span>
</code></pre></div><h4 id="model"><strong>Model</strong></h4>
<p><strong>1) Model Structure Building</strong></p>
<p>The encoder takes input features of 39 days (t<em>1, t</em>2 … t39) and encode their hidden states through LSTM neural network. Then it pass the hidden states to decoder. Decoder use them with the features of 39 days shifted 1 day forward (t<em>2, t</em>3 … T40) to predict number of visitors per each of 829 restaurants in t_40.</p>
<p>Methods used to address overfitting: we applied dropout and recurrent dropout regularization in all RNN layers and adjust the epoch size to prevent overfitting.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># MODEL FOR ENCODER AND DECODER -------------------------------------------</span>
<span class="n">num_encoder_tokens</span> <span class="o">=</span> <span class="n">X_lstm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">latent_dim</span> <span class="o">=</span> <span class="mi">256</span>

<span class="c1"># encoder training</span>
<span class="n">encoder_inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">num_encoder_tokens</span><span class="p">))</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span>
               <span class="n">batch_input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">num_encoder_tokens</span><span class="p">),</span>
               <span class="n">stateful</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
               <span class="n">return_sequences</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
               <span class="n">return_state</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
               <span class="n">recurrent_initializer</span> <span class="o">=</span> <span class="s1">&#39;glorot_uniform&#39;</span><span class="p">)</span>

<span class="n">encoder_outputs</span><span class="p">,</span> <span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span> <span class="o">=</span> <span class="n">encoder</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">)</span>
<span class="n">encoder_states</span> <span class="o">=</span> <span class="p">[</span><span class="n">state_h</span><span class="p">,</span> <span class="n">state_c</span><span class="p">]</span> <span class="c1"># &#39;encoder_outputs&#39; are ignored and only states are kept.</span>

<span class="c1"># Decoder training, using &#39;encoder_states&#39; as initial state.</span>
<span class="n">decoder_inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">num_encoder_tokens</span><span class="p">))</span>

<span class="n">decoder_lstm_1</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,</span>
                      <span class="n">batch_input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">num_encoder_tokens</span><span class="p">),</span>
                      <span class="n">stateful</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
                      <span class="n">return_sequences</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                      <span class="n">return_state</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
                      <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span>
                      <span class="n">recurrent_dropout</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">)</span> <span class="c1"># True</span>

<span class="n">decoder_lstm_2</span> <span class="o">=</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span>
                     <span class="n">stateful</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
                     <span class="n">return_sequences</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                     <span class="n">return_state</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                     <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span>
                     <span class="n">recurrent_dropout</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">)</span>

<span class="n">decoder_outputs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">decoder_lstm_2</span><span class="p">(</span><span class="n">decoder_lstm_1</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">,</span> <span class="n">initial_state</span> <span class="o">=</span> <span class="n">encoder_states</span><span class="p">))</span>
<span class="n">decoder_dense</span> <span class="o">=</span> <span class="n">TimeDistributed</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">Y_lstm</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">decoder_dense</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">)</span>

<span class="c1"># training model</span>
<span class="n">training_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">decoder_inputs</span><span class="p">],</span> <span class="n">decoder_outputs</span><span class="p">)</span>
<span class="n">training_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span> <span class="o">=</span> <span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="s1">&#39;mean_squared_error&#39;</span><span class="p">)</span>

<span class="c1"># GENERATOR APPLIED TO FEED ENCODER AND DECODER ---------------------------</span>
<span class="c1"># generator that randomly creates times series of 39 consecutive days</span>
<span class="c1"># theses time series has following 3d shape: 829 restaurants * 39 days * num_features</span>
<span class="k">def</span> <span class="nf">dec_enc_n_days_gen</span><span class="p">(</span><span class="n">X_3d</span><span class="p">,</span> <span class="n">Y_3d</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
    <span class="k">while</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">decoder_boundary</span> <span class="o">=</span> <span class="n">X_3d</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="n">encoder_start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">decoder_boundary</span><span class="p">)</span>
        <span class="n">encoder_end</span> <span class="o">=</span> <span class="n">encoder_start</span> <span class="o">+</span> <span class="n">length</span>

        <span class="n">decoder_start</span> <span class="o">=</span> <span class="n">encoder_start</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">decoder_end</span> <span class="o">=</span> <span class="n">encoder_end</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">X_to_conc</span> <span class="o">=</span> <span class="n">X_3d</span><span class="p">[:,</span> <span class="n">encoder_start</span><span class="p">:</span><span class="n">encoder_end</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">Y_to_conc</span> <span class="o">=</span> <span class="n">Y_3d</span><span class="p">[:,</span> <span class="n">encoder_start</span><span class="p">:</span><span class="n">encoder_end</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">X_to_decode</span> <span class="o">=</span> <span class="n">X_3d</span><span class="p">[:,</span> <span class="n">decoder_start</span><span class="p">:</span><span class="n">decoder_end</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">Y_decoder</span> <span class="o">=</span> <span class="n">Y_3d</span><span class="p">[:,</span> <span class="n">decoder_start</span><span class="p">:</span><span class="n">decoder_end</span><span class="p">,</span> <span class="p">:]</span>

        <span class="k">yield</span><span class="p">([</span><span class="n">X_to_conc</span><span class="p">,</span>
               <span class="n">X_to_decode</span><span class="p">],</span>
               <span class="n">Y_decoder</span><span class="p">)</span>


</code></pre></div><p><strong>2) Generator applied to feed encoder and decoder</strong></p>
<p>Our  generator that randomly creates times series of 39 consecutive days. And those time series has following 3-D shape: 829 restaurants * 39 days * num_features.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">dec_enc_n_days_gen</span><span class="p">(</span><span class="n">X_3d</span><span class="p">,</span> <span class="n">Y_3d</span><span class="p">,</span> <span class="n">length</span><span class="p">):</span>
    <span class="k">while</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">decoder_boundary</span> <span class="o">=</span> <span class="n">X_3d</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">length</span> <span class="o">-</span> <span class="mi">1</span>

        <span class="n">encoder_start</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">decoder_boundary</span><span class="p">)</span>
        <span class="n">encoder_end</span> <span class="o">=</span> <span class="n">encoder_start</span> <span class="o">+</span> <span class="n">length</span>

        <span class="n">decoder_start</span> <span class="o">=</span> <span class="n">encoder_start</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">decoder_end</span> <span class="o">=</span> <span class="n">encoder_end</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">X_to_conc</span> <span class="o">=</span> <span class="n">X_3d</span><span class="p">[:,</span> <span class="n">encoder_start</span><span class="p">:</span><span class="n">encoder_end</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">Y_to_conc</span> <span class="o">=</span> <span class="n">Y_3d</span><span class="p">[:,</span> <span class="n">encoder_start</span><span class="p">:</span><span class="n">encoder_end</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">X_to_decode</span> <span class="o">=</span> <span class="n">X_3d</span><span class="p">[:,</span> <span class="n">decoder_start</span><span class="p">:</span><span class="n">decoder_end</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">Y_decoder</span> <span class="o">=</span> <span class="n">Y_3d</span><span class="p">[:,</span> <span class="n">decoder_start</span><span class="p">:</span><span class="n">decoder_end</span><span class="p">,</span> <span class="p">:]</span>

        <span class="k">yield</span><span class="p">([</span><span class="n">X_to_conc</span><span class="p">,</span>
               <span class="n">X_to_decode</span><span class="p">],</span>
               <span class="n">Y_decoder</span><span class="p">)</span>
</code></pre></div><p><strong>3) Training the model</strong></p>
<p>Training on X_tr/Y_tr and validate with X_val/Y_val. To perform validation training on validation data should be made instead of training on full data set. Then validation check is made on period outside of training data</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="s1">&#39;&#39;&#39;
</span><span class="s1">training_model.fit_generator(dec_enc_n_days_gen(X_tr, Y_tr, 39),
</span><span class="s1">                             validation_data = dec_enc_n_days_gen(X_val, Y_val, 39),
</span><span class="s1">                             steps_per_epoch = X_lstm.shape[0],
</span><span class="s1">                             validation_steps = X_val.shape[0],
</span><span class="s1">                             verbose = 1,
</span><span class="s1">                             epochs = 1)
</span><span class="s1">&#39;&#39;&#39;</span>

<span class="c1"># Training on full dataset</span>
<span class="n">training_model</span><span class="o">.</span><span class="n">fit_generator</span><span class="p">(</span><span class="n">dec_enc_n_days_gen</span><span class="p">(</span><span class="n">X_lstm</span><span class="p">[:,:,:],</span> <span class="n">Y_lstm</span><span class="p">[:,:,:],</span> <span class="mi">39</span><span class="p">),</span>
                            <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">X_lstm</span><span class="p">[:,:,:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">verbose</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                            <span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</code></pre></div><p><strong>4) Perform Prediction</strong></p>
<p>The function takes 39 days before first prediction day (input_seq), then using encoder to identify hidden states for these 39 days. Next, decoder takes hidden states provided by encoder, and predicts number of visitors from day 2 to day 40. Day 40 is the first day of target_seq.</p>
<p>Predicted value for day 40 is appended to features of day 41. Then function takes period from day 2 to day 40 and repeat the process unil all days in target sequence get their predictions.</p>
<p>The output of the function is the vector with predictions that has following shape: 820 restaurants * 39 days * 1 predicted visitors amount</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">predict_sequence</span><span class="p">(</span><span class="n">inf_enc</span><span class="p">,</span> <span class="n">inf_dec</span><span class="p">,</span> <span class="n">input_seq</span><span class="p">,</span> <span class="n">Y_input_seq</span><span class="p">,</span> <span class="n">target_seq</span><span class="p">):</span>
    <span class="c1"># state of input sequence produced by encoder</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">inf_enc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">input_seq</span><span class="p">)</span>

    <span class="c1"># restrict target sequence to the same shape as X_lstm_test</span>
    <span class="n">target_seq</span> <span class="o">=</span> <span class="n">target_seq</span><span class="p">[:,:,</span> <span class="p">:</span><span class="n">X_lstm_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>


    <span class="c1"># create vector that contains y for previous 7 days</span>
    <span class="n">t_minus_seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">Y_input_seq</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">:,:],</span> <span class="n">input_seq</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">:,</span> <span class="n">X_lstm_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># current sequence that is going to be modified each iteration of the prediction loop</span>
    <span class="n">current_seq</span> <span class="o">=</span> <span class="n">input_seq</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>


    <span class="c1"># predicting outputs</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="n">target_seq</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">target_seq</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="c1"># add visitors for previous 7 days into features of a new day</span>
        <span class="n">new_day_features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">target_seq</span><span class="p">[:,</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,:],</span> <span class="n">t_minus_seq</span><span class="p">[</span><span class="o">...</span><span class="p">]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># move prediction window one day forward</span>
        <span class="n">current_seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">current_seq</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:,:],</span> <span class="n">new_day_features</span><span class="p">[:,]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>


        <span class="c1"># predict visitors amount</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">inf_dec</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">current_seq</span><span class="p">]</span> <span class="o">+</span> <span class="n">state</span><span class="p">)</span>

        <span class="c1"># update t_minus_seq</span>
        <span class="n">t_minus_seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">pred</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">:,:],</span> <span class="n">t_minus_seq</span><span class="p">[</span><span class="o">...</span><span class="p">]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">t_minus_seq</span> <span class="o">=</span> <span class="n">t_minus_seq</span><span class="p">[:,:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>        

        <span class="c1"># update predicitons list</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">output</span><span class="p">[</span><span class="o">...</span><span class="p">],</span> <span class="n">pred</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">:,:]),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># update state</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">inf_enc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">current_seq</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">output</span><span class="p">[:,</span><span class="mi">1</span><span class="p">:,:]</span>

<span class="c1"># inference encoder</span>
<span class="n">encoder_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">encoder_inputs</span><span class="p">,</span> <span class="n">encoder_states</span><span class="p">)</span>

<span class="c1"># inference decoder</span>
<span class="n">decoder_state_input_h</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,))</span>
<span class="n">decoder_state_input_c</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,))</span>
<span class="n">decoder_states_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">decoder_state_input_h</span><span class="p">,</span> <span class="n">decoder_state_input_c</span><span class="p">]</span>
<span class="n">decoder_outputs</span><span class="p">,</span><span class="n">_</span><span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">decoder_lstm_2</span><span class="p">(</span><span class="n">decoder_lstm_1</span><span class="p">(</span><span class="n">decoder_inputs</span><span class="p">,</span>
                                                    <span class="n">initial_state</span> <span class="o">=</span> <span class="n">decoder_states_inputs</span><span class="p">))</span>
<span class="n">decoder_outputs</span> <span class="o">=</span> <span class="n">decoder_dense</span><span class="p">(</span><span class="n">decoder_outputs</span><span class="p">)</span>
<span class="n">decoder_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">([</span><span class="n">decoder_inputs</span><span class="p">]</span> <span class="o">+</span> <span class="n">decoder_states_inputs</span><span class="p">,</span>
                      <span class="p">[</span><span class="n">decoder_outputs</span><span class="p">])</span>

<span class="c1"># Predicting test values</span>
<span class="n">enc_dec_pred</span> <span class="o">=</span> <span class="n">predict_sequence</span><span class="p">(</span><span class="n">encoder_model</span><span class="p">,</span>
                                <span class="n">decoder_model</span><span class="p">,</span>
                                <span class="n">X_lstm</span><span class="p">[:,</span><span class="o">-</span><span class="n">X_lstm_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:,:],</span>
                                <span class="n">Y_lstm</span><span class="p">[:,</span><span class="o">-</span><span class="n">X_lstm_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:,:],</span>
                                <span class="n">X_lstm_test</span><span class="p">[:,:,:])</span>
</code></pre></div><h3 id="evaluation">Evaluation</h3>
<p>Finally, we aggregated the prediction of both LGBM and seq2seq, which enabled us to get the best evaluation metric:</p>
<table>
<thead>
<tr>
<th align="left">Models Name</th>
<th>ERROR(RMSLE)</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">ARIMA.</td>
<td>0.56137</td>
</tr>
<tr>
<td align="left">PROPHET</td>
<td>0.54208</td>
</tr>
<tr>
<td align="left">LIHGT GBM(LGBM)</td>
<td>0.52412</td>
</tr>
<tr>
<td align="left">LSTM SEQ2SEQ</td>
<td>0.50277</td>
</tr>
<tr>
<td align="left"><strong>LSTM + LGBM</strong></td>
<td><strong>0.50002</strong></td>
</tr>
</tbody>
</table>
<p>The metric used to evaluate our model is RMSLE (root mean squared logarithmic error)
$$
\sqrt{\frac{1}{n} \sum_{i=1}^n (\log(p_i + 1) - \log(a_i+1))^2 }
$$
where:</p>
<p>n  is the total number of observations
p_i is the prediction of visitors
a_i is the actual number of visitors</p>
<p>We chose this metric for the following reasons:</p>
<ul>
<li>First, we care about percentage errors more than the absolute value of errors.</li>
<li>Second, we want to penalize under estimating the number of visitors more than overestimating it, because underestimating will lead to a bad customer experience which is our top priority.</li>
</ul>
<h2 id="4-business-insight">4. Business Insight</h2>
<p>Normally we would provide recommendations in this section. Because we are only looking to sell our system in this project, we are instead providing reasons for why someone should buy our product.</p>
<p>We are looking to persuade a restaurant owner to purchase our product. For them, the decision ultimately comes down to: &ldquo;How much will these predictions actually help me out? I believe I know the business and have good intuition about how many people will come to the restaurant. Are their predictions any better than me? How much money will they save for me?&rdquo;</p>
<p>To quantify this, we decided to run a couple of simulations on our training data based on intuition to see how good our results would be. For reference, our daily percent error (using MAPE) was 50%.</p>
<ol>
<li>
<p>Using the previous day, the manager would be off by 113% on average.</p>
</li>
<li>
<p>Using the same weekday from the previous week, the manager would be off by 94% on average.</p>
</li>
</ol>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># One day</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;prev_day_visitors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;visitors_x&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">group</span><span class="p">:</span> <span class="n">group</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">])</span>
<span class="c1"># One week</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;prev_week_visitors&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;visit_date&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">weekday</span><span class="p">])[</span><span class="s1">&#39;visitors_x&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shift</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;air_store_id&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">group</span><span class="p">:</span> <span class="n">group</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">7</span><span class="p">:,</span> <span class="p">])</span>
<span class="c1"># Error</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;difference_decimal&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;visitors_x&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;prev_day_visitors&#39;</span><span class="p">])</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;visitors_x&#39;</span><span class="p">]</span>
</code></pre></div><p><strong>Staffing</strong></p>
<p>The hourly minimum wage in Japan translates to roughly <a href="https://tradingeconomics.com/japan/minimum-wages" target="_blank" rel="noopener noreffer">$8.30 USD</a>. Overstaffing by 2 people for a given 8-hour day equates to roughly $130 in unnecessary expenses. On the flip side, understaffing means a poor customer experience as wait time is longer. We believe this provides strong support for the purchase of our system.</p>
<p><strong>Supply Chain</strong></p>
<p>Although we are not able to quantify the supply chain as easily as we can with staffing costs, owners are able to reduce expenses if they have a more accurate picture of how many customers they expect to see. Purchasing too much leads to waste, and purchasing too little means running out of ingredients and making your customers upset. Using our system provides a more stable data-driven approach to this problem.</p>
<p><strong>Smoothing Demand</strong></p>
<p>Although not covered in our project, an individual will be able to look at their past data and gain an unbiased view of seasonality that occurs throughout the year. If they are looking for stability week-by-week or month-by-month to even out their supply purchases or keep the correct number of people on board, they can use their past data to aid in offering of incentives to drive customers where they see fit.</p>
<p><strong>Important Features</strong></p>
<p>Another insight we can provide the manager is an understanding of the most important features that drives their business. In particular, we found the following 5 to be most important when we ran our LightGBM model:</p>
<p><strong>(1) Previous year mapping</strong></p>
<p><strong>(2) Days since previous 25th</strong></p>
<p><strong>(3) Holiday flag</strong></p>
<p><strong>(4) Aggregated visitors per day of week</strong></p>
<p><strong>(5) Exponential Moving Average</strong></p>
<h2 id="5-limitations--next-steps">5. Limitations &amp; Next Steps</h2>
<p>To address the limitations of our predictive models, we could focus on the following dimensions to improve model performance.</p>
<p><strong>Feature Improvement</strong></p>
<p>We could pay more attention to feature engineering. We could include weather data in our model since the weather condition is likely to affect restaurant traffic.  In addition, the distance of a restaurant to the busiest area might also contribute to the prediction of visiting frequency. Restaurants in busy areas are likely to have more traffic than those in suburb areas.  We could also improve upon the feature selection process. The light GBM method provides the  importance of each feature. Using this information, we are able to either remove unimportant features or add additional features that are similar to important features.</p>
<p><strong>Modeling Improvement</strong></p>
<p>We also could improve the modeling process. In order to improve the performance of RNN models such as LSTM, we could choose to apply attention mechanisms to current RNN models. Besides, when using ensembling method, we could try to combine more diverse models so that the performance of ensembling model is better than the performance of individual models.</p>
<p><strong>Expand the Timespan</strong></p>
<p>Our current model is trained on data of 2-year time period. If we are able to collect data of longer time span and train our model on the enriched dataset, our model might be able to generate more accurate predictions.</p>
<p><img
        class="lazyload"
        src="/svg/loading/small.min.svg"
        data-src="https://images.unsplash.com/photo-1557395714-5177be073e2b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1587&amp;q=80"
        data-srcset="https://images.unsplash.com/photo-1557395714-5177be073e2b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1587&amp;q=80, https://images.unsplash.com/photo-1557395714-5177be073e2b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1587&amp;q=80 1.5x, https://images.unsplash.com/photo-1557395714-5177be073e2b?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=1587&amp;q=80 2x"
        data-sizes="auto"
        alt="https://images.unsplash.com/photo-1557395714-5177be073e2b?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1587&q=80"
        title="https://images.unsplash.com/photo-1557395714-5177be073e2b?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1587&q=80" /></p>
<h2 id="references">References</h2>
<p><a href="https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html">https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html</a>
<a href="https://github.com/Arturus/kaggle-web-traffic">https://github.com/Arturus/kaggle-web-traffic</a>
<a href="https://github.com/MaxHalford/kaggle-recruit-restaurant/blob/master/Solution.ipynb">https://github.com/MaxHalford/kaggle-recruit-restaurant/blob/master/Solution.ipynb</a>
<a href="https://www.kaggle.com/pureheart/1st-place-lgb-model-public-0-470-private-0-502">https://www.kaggle.com/pureheart/1st-place-lgb-model-public-0-470-private-0-502</a>
<a href="https://www.kaggle.com/plantsgo/solution-public-0-471-private-0-505">https://www.kaggle.com/plantsgo/solution-public-0-471-private-0-505</a>
<a href="https://www.kaggle.com/h4211819/holiday-trick">https://www.kaggle.com/h4211819/holiday-trick</a>
<a href="https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/49100">https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/49100</a></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span></span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="https://hyper-potato.github.io/2019-11-12-restaurants-visitors-predictive-model/" data-title="Predicting Visitors for Restaurants" data-hashtags="machine learning,Time Series Forecasting,regression"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="https://hyper-potato.github.io/2019-11-12-restaurants-visitors-predictive-model/" data-hashtag="machine learning"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on Linkedin" data-sharer="linkedin" data-url="https://hyper-potato.github.io/2019-11-12-restaurants-visitors-predictive-model/"><i class="fab fa-linkedin fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/machine-learning/">machine learning</a>,&nbsp;<a href="/tags/time-series-forecasting/">Time Series Forecasting</a>,&nbsp;<a href="/tags/regression/">regression</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/2019-11-02-money-ball-with-arules/" class="prev" rel="prev" title="Moneyball on Dortmund with Association Rules"><i class="fas fa-angle-left fa-fw"></i>Moneyball on Dortmund with Association Rules</a>
            <a href="/2019-11-28-cat-or-dog-classification-dnn/" class="next" rel="next" title="Cats vs Dogs Classification">Cats vs Dogs Classification<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2020</span><span class="author" itemprop="copyrightHolder">&nbsp;
                      Nina</div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript">
    window.config = {"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"headerMode":{"desktop":"fixed","mobile":"auto"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};
</script><script type="text/javascript" src="https://polyfill.io/v3/polyfill.min.js?features=html5shiv%2CElement.prototype.closest%2CrequestAnimationFrame%2CCustomEvent%2CPromise%2CObject.entries%2CObject.assign%2CObject.values%2Cfetch%2CElement.prototype.after%2CArray.prototype.fill%2CIntersectionObserver%2CArray.from%2CArray.prototype.find%2CMath.sign"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/object-fit-images/ofi.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
